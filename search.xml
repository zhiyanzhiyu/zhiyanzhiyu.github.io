<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ML003.单变量线性回归]]></title>
    <url>%2F2018%2F07%2F30%2Fai-ml-003-single-regression%2F</url>
    <content type="text"><![CDATA[Machine Learing学习笔记，主要参考Andrew Ng、李宏毅等大牛的课程和书籍。本文是0003篇之单变量线性回归的相关内容，主要参考Ng的机器学习教程。 1 模型表述本文是斯坦福机器学习课程2-1节的笔记，主要内容是对机器学习问题，如何进行建模表述？在这部分内容，在前面一篇笔记中，已经有过说明，这里在根据Ng的课程重新说明一下，以便加深理解。 在房价预测案例中，我们有一个数据集，包含某地住房价格。如下： 根据该数据集，我们可以在坐标图上画出相应的数据集。很自然的，我们要想预测该地区的房价，就是在该坐标图上求解一条直线或者曲线，而这条线会尽可能多的穿过历史交易数据的点。 在上述问题表述中，有几个常见的术语需要明确一下：房屋面积是数据的特征（feature）,某一条历史交易数据都是一个训练样本（training example）,所有的历史交易数据叫做训练集（training set）。 通过过把训练集输入给学习算法，进而学习得到一个假设的 h，然后将要预测的房屋尺寸作为输入变量输入给 h，预测出该房屋的交易价格作为输出变量输出为结果，如下图所示： 问题需要用数学的方式表述出来，其中： m代表训练集中样本数量； x代表特征/输入变量； y代表目标变量/输出变量； $\langle x,y\rangle$代表训练集中的样本实例； $\langle x_\langle i_\rangle ,y_\langle i_\rangle \rangle$代表第 i 个观察样本； h 代表学习算法的解决方案或函数，也称为假设(hypothesis) 。 那么我们如何来找到这个h呢？房价预测的例子比较简单，h 表示一个函数，输入x是房屋尺寸大小，因此h根据输入的x值来得出y值，y值对应房子的价格，h是一个从x 到y的函数映射。 因为这个函数只含有一个特征/输入变量，这样的问题叫作单变量线性回归问题。现在要做的便是为我们的模型选择合适的参数(parameters)$\theta_0$ 和$\theta_1$ 。很明显，在房价预测这个例子中，$θ_1$便是直线的斜率，$θ_1$则是在 y 轴上的截距，求解这两个参数是后续成本函数所要解决的问题。 2 代价函数本文是斯坦福大学机器学习课程的2-2，2-3，2-4的学习笔记，主要是内容是代价函数以及对代价函数的直观理解。 2.1 代价函数定义（Cost Function ）如下图所示，在房价预测的案例中，我们得到了预测房价的目标函数，问题也转换成了为模型选择合适的参数$\theta_i$$，即$$θ_0$和$θ_1$。 思路是通过选取不同的$（θ_0,θ1）$使得$h\theta\langle x \rangle $更接近与y,就是$h_\theta\langle x \rangle $和训练集的真实值的误差最小，当这个误差最小的时候，就是我们要的参数值。 通过这个思路，我们得到了一个关于$\langleθ_0,θ_1\rangle$的函数，当这个函数取得最小值的时候，我们就找到了我们要的参数值。 代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。对于大多数问题特别是回归问题，平方误差代价函数都是一个合理的选择。 2.2 代价函数的直观理解我们要进一步解释代价函数 $J\langle\theta_0,\theta_1 \rangle$的工作原理 ，并尝试更直观地解释它在计算什么，以及我们使用它的目的。为了更好的进行说明理解，我们先对问题进行简化，即设置$θ_0$=0。 $h_\theta\langle x \rangle $是一条穿过原点的直线，而代价函数则是一条曲线，当这条曲线取最小值得时候，得到最佳的$h_\theta\langle x \rangle $。 2.3 代价函数的直观理解2当我们不对问题进行简化，保留$\theta_0$的时候,问题会复杂一些，$h_\theta\langle x \rangle $是一条不经过原点的直线。 对应的代价函数则是一个3D曲面图（弓形函数），$θ_0,θ_1$是平面上的两个坐标，而高度则是 $J\langle\theta_0,\theta_1 \rangle$的值。 不过为了使得问题更容易理解，可以使用等高线图来表示代价函数，两者是等价的。可以看出等高线最低点的取值，就是 $J\langle\theta_0,\theta_1 \rangle$的最小值，而此时是拟合训练数据最多的一条直线。 2.4 如何自动求解 $J\langle\theta_0,\theta_1 \rangle$最小值？求得$\langle\theta_0,\theta_1 \rangle$的最小值，也就得到了最佳的$\langle\theta_0,\theta_1 \rangle$值，也就得到了最佳$$h_\theta\langle x \rangle $。不过在实际问题中，我们不可能把这些点画出来，然后用人工的方法来读出这些点的数值。我们会遇到更复杂、更高维度、更多参数的情况，而这些情况是很难画出图的，因此更无法将其可视化，因此我们真正需要的是编写程序，自动的找出这些最小化代价函数的参数值。 最后，课程检测里看到一道思考题：如果存在 $J\langle\theta_0,\theta_1 \rangle$ = 0，意味着什么呢？ 原点？ 3 梯度下降本文是斯坦福大学机器学习第2-5，2-6，2-7，2-8几个小节的学习笔记，主要内容是梯度下降算法。 3.1 梯度下降算法梯度下降是一个用来求函数最小值的算法，思路是先随机选择一个参数组合计算代价函数，然后寻找下一个能让代价函数值下降最多的参数组合，然后重复执行此操作，直到找到一个局部最小值(local minimum)。 因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值(global minimum)，选择不同的初始参数组 合，可能会找到不同的局部最小值。这里我们可以想象一下，如果自己站在一座山上的某个点，怎么来找到最短的下山路径？ 梯度下降算法表示如下： 其中 α 是学习率(learning rate)，它决定了代价函数下降程度，即向下迈出的步子有多大。 在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数，即我们要更新$θ_0$ 和$θ_1$，同时更新是梯度下降中的一种常用方法，当我们谈到梯度下降时，默认就是同步更新。 3.2 梯度下降的直观意义在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。对θ赋值，使得$ J\langleθ\rangle$ 按梯度下降最快方向进行，一直迭代下去，最终得到局部 最小值。其中 a 是学习率(learning rate)，它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。 如下图上半部分所示，求导就是说取这个红点的切线，这条切线的斜率正好是这个三角形的高度除以这个水平长度。现在这条线有一个正斜率，也就是说它有正导数，因此我得到的新的$θ_1$ ，$θ_1$ 更新后等于$θ_1$ 减去一 个正数乘以 a ，所以下一个θ值会变小。 相反，如果$θ_1$取在左边一点，那么求得导数就是一个负导数，下一个θ值会变大。 如果 a 太小或 a 太大会出现什么情况呢？所以如果 a 太小的话，梯度下降会很慢，需要很多步才能到达全局最低点。如果 a 太大有可能会越过最低点，甚至可能无法收敛，甚至发散。如下图所示： 局部最低点问题：如果我们预先把$θ_1$ 放在一个局部的最低点，你认为下一步梯度下降法会怎样工作?因为局部最优点的导数将等于零，这意味着新的$θ_1$ 等于原来的$θ_1$，那么梯度下降法更新其实什么都没做。这也解释了为什么即使学习速率 a 保持不变时，梯度下降可以收敛到局部最低点。 在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，因为当我们接近局部最低点时会导数逐渐趋近于零，因此没有必要再另外减小 a 。 3.3 线性回归的梯度下降下面将梯度下降和代价函数结合，将其应用于具体的拟合直线的线性回归算法里。 其实就是梯度下降算法里面$ J\langleθ\rangle$换成具体的代价函数，然后进行迭代计算，直到取得代价函数的最小值。下面几张截图说明了该过程： 如果不特别指明，梯度下降指的是批量梯度下降，即在梯度下降的每一步中，我们都用到了所有的训练样本。在梯度下降中，在计算微分求导项时，我们需要进行求和运算。在每一个单独的梯度下降中，都要要对所有 m 个训练 样本求和。可以想象的到，当样本很大时梯度下降的效率相当大，因此也有不是这种”批量”型的梯度下降，不考虑整个的训练集，每次只关注训练集中的一些小的子集。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>统计学习</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ML002.统计学习方法概论]]></title>
    <url>%2F2018%2F07%2F30%2Fai-ml-002-statisical-ml-outline%2F</url>
    <content type="text"><![CDATA[Machine Learing学习笔记，主要参考Andrew Ng、李宏毅等大牛的课程和书籍。本文是003篇之统计学习方法概论，主要内容是李航《统计学习方法》第一章的内容，统计学习方法概论，介绍了一些基本概念。 在前面的一篇笔记中，提到过机器学习和统计学的关系：统计学的目的是通过学习更多的潜在模式和关联关系，来帮助人类深入理解数据。 统计学习近似于机器学习，与机器学习高度重合，统计学的发展促进了机器学习的大发展，但是两者侧重点不同。统计学习重点关注统计模型的发展优化，偏数学，而机器学习关注实际问题的解决，偏实际。 机器学习和统计学习各有侧重，不过对我们初学者来说，可以把两者先当成一回事。最近也在看李航的那本《统计学习方法》，虽然是一本很薄的书，但是对我这种数学渣渣来说，真的看着有些吃力了。不过其评分之高是我们不能回避的一本书。 网上大部分视频课程都是采用的一种从简单例子开始，自下而上的方式，但是这样在学习的过程中，总是会不断的出现新的概念，时间长了就有点混乱，不够系统。而《统计学习方法》的第一章可以很好的给我们一个自顶而下的概念，让我们能够更加系统的掌握相关概念。本文算是该书第一章的读书笔记。 1.统计学习的定义和特点统计学习统计机器学习（Statisical Machine Learning，是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。它有如下几个特点： 计算机及网络平台之上，这个自然，不需多言； 以数据为研究对象，数据驱动，是统计学习的对象； 预测与分析，这是统计学习的目标； 方法为中心，所谓的方法就是前一篇笔记的模型和算法，比如监督学习，无监督学习，半监督学习以及强化学习等等。 概率论，统计学，信息论，计算理论，最优化理论及计算机科学 交叉学科。 上述内容都比较好理解，需要重点说明的是学习方法相关的内容：统计学习方法包括模型的假设空间，模型选择的准则以及模型学习的算法，这三者被称为统计学习的三要素，简称模型，策略和算法。 实现统计学习方法的步骤： 得到一个有限的训练数据集合； 确定包含所有可能的模型的假设空间，即学习模型的集合； 确定模型选择的准则，即学习的策略； 实现求解最优模型的算法，即学习的算法； 通过学习方法选择最优模型； 利用学习的最优模型对新数据进行预测分析。 2 监督学习Supervised learning，李航的《统计学习方法》主要讲的监督学习。 2.1 基本概念输入空间与输出空间：在监督学习中，将输入与输出所有可能的取值的集合分别称为输入空间（input space）与输出空间（output space）,输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。通常输出空间远小于输入空间。 特征空间： 每个具体的输入都是一个实例（instance）,通常由特征向量（feature vector）表示,所有特征向量存在的空间成为特征空间（feature space）。特征空间的每一维都对应于一个特征。有时假设输入空间与特征空间为相同的空间，有时假设输入空间与特征空间为不同的空间，需要将实例从输入空间映射到特征空间。模型实际上都是定义在特征空间上的。 通常情况下，输入变量写作X，输出变量写作Y，输入实例x的特征向量记作：$x = (x^{(1)},x^{(2)},…,x^{(x)})^T$,其中$x^{(i)}$表示x的第i个特征，注意与$x_i$的区分，$x_i$表示多个输入变量中的第i个，即：$x_i = (x_i^{(1)},x_i^{(2)},…,x_i^{(n)})^T$。 训练集通常表示为：$T = {(x_1,y_1),(x_2,y_2),…,(x_n,y_n) }$，输入与输出对又称为样本（Sample）或者样本点。 输入变量X和输出变量Y有不同的类型，可以是连续的，也可以是离散的。通常分为如下三类： 输入变量与输出变量均为连续变量的预测问题成为回归问题； 输出变量为有限个离散变量的预测问题称为分类问题； 输入变量与输出变量均为变量序列的预测问题成为标注问题； 联合概率分布监督学习假设输入与输出的随机变量X和Y遵循联合概率分布$P(X,Y)$,$P(X,Y)$表示分布函数，或者分布密度函数。需要注意的是：在学习过程中，我们假定这一联合概率分布存在，但是对学习系统来说，联合概率分布的具体定义是未知的。统计学习假设数据存在一定统计规律，X和Y具有联合概率分布的假设就是监督学习关于数据的基本假设。 假设空间 监督学习的目的在于找到一个由输入到输出的映射，即所谓的模型。学习的目的是找到一个最好的模型，模型属于输入空间到输出的空间映射的集合，这个集合就是假设空间（hypothesis space）,假设空间的确定意味着学习范围的确定。 监督学习的模型一般由条件概率分布$P(X|Y)$或者决策函数(decision function) $ Y = f(X)$ 表示，对具体输入进行相应的预测时，写作：$P(y|x)$ 或$y = f(x)$ 2.2 问题的形式化 在学习过程中，系统利用给定训练数据，学习（训练）得到一个模型，表示为条件概率分布【】或者决策函数，用来描述输入与输出随机变量之间的映射关系。 在学习过程中，学习系统试图通过训练数据集中的样本$\langle x_i,y_i \rangle$带来的信息学习模型。具体地说，对输入$x_i$，一个具体的模型$y = f(x)$ 可以产生一个输出$f(x_i)$,而训练数据集中对应的输出是$y_i$，如果这个模型有很好的预测能力，训练样本输出$y_i$和模型输出之间的差应该足够小。学习系统通过不断的尝试，选取最好的模型，以便对训练数据集有足够好的预测，同时对未知的测试数据集的预测也有尽可能好的推广。 3 统计学习三要素统计学习方法 = 模型 + 策略 + 算法 3.1模型条件概率分布或决策函数，模型的假设空间包含所有可能的条件概率分布或决策函数。J假设空间中的模型一般有无穷多个。 假设空间可以定义为决策函数的集合：$F = {f|Y=f(x)}$,其中X和Y事定义在输入空间和输出空间上的变量，参数向量觉得的函数族：$F = {f|Y=f_\theta(X),\theta \in R^n }$,参数向量$\theta$ 取值于n维欧氏空间$R^n$,成为参数空间。 3.2 策略有了模型空间，需要考虑按照什么样的准则学习或选择最优的模型？损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。 损失函数 Loss function cost function ， 在假设空间中选取模型f作为决策函数，对于给定的输入X，由f(X)给出响应的输出Y，这个输出的预测值f(X)和Y之间可能一致也可能不一致，用一个损失函数或者代价函数来度量预测错误的程度，记作：$L(Y,f(X))$，损失函数是f(X)和Y的非负实值函数。 常用损失函数： 0-1损失函数 平方损失函数 绝对损失函数 对数损失函数 风险函数 损失函数值越小，模型就越好。 风险函数，期望损失，病态问题 经验风险 经验损失 多岁期望风险是模型关于联合分布的期望损失，经验风险是模型关于训练样本集的平均损失。根据大数定律，当样本容量N趋于无穷大时，经验风险趋于期望风险。 经验风险最小化 在样本足够大时，经验风险最小化能保证有很好的学习效果，被广泛采用。极大似然估计就是经验风险最小化的一个例子。但是当样本容量小时，容易产生过拟合现象。 结构风险最小化 结构风险最小化（Structural risk minimization,SRM）是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化（regularization）。结构风险在经验风险上加上表示模型复杂度的正则化项（regularizer）或罚项（penalty term)。在假设空间，损失函数以及训练数据集确定的情况下，结构风险的定义是： $$R_{srm}(f) = \frac{1}{N} \sum_{i=1}^n L(y_i,f(x_i)) +\lambda J(f)$$ 其中，$J(f)$为模型复杂度，定义在假设空间上的泛函数。模型$f$越复杂，复杂度就越大。复杂度表示了复杂模型的惩罚。$\lambda$ 大于等于0，权衡经验风险和复杂度模型。贝叶斯估计中最大后验概率估计是结构风险最小化的例子。 结构风险最小化的策略认为架构风险最小的模型是最优模型，所以求最优模型就是求解最优化问题： $$min_{f} \frac{1}{N} \sum_{i=1}^n L(y_i,f(x_i)) +\lambda J(f)$$ 3.3 算法学习模型的具体计算方法，比如梯度下降算法。 4 模型评估与模型选择4.1 训练误差和测试误差 训练误差 训练数据 测试误差 测试数据 泛化能力 将学习方法对未知数据的预测能力称为泛化能力（generalization ability） 4.2 过拟合与模型选择 过拟合（over-fitting） 5 正则化与交叉验证5.1 正则化模型选择的典型方法是正则化（regularzation）,正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或惩罚项。 正则化的作用是选择经验风险与模型复杂度同时较小的模型。正则化符合奥卡姆剃刀（Occam’s razor）原理。奥卡姆剃刀原理应用于模型选择时考虑：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单的才是最好的模型，也就是应该选择的模型。 奥卡姆剃刀定律（Occam’s Razor, Ockham’s Razor）又称“奥康的剃刀”，它是由14世纪英格兰的逻辑学家、圣方济各会修士奥卡姆的威廉（William of Occam，约1285年至1349年）提出。这个原理称为“如无必要，勿增实体”，即“简单有效原理”。正如他在《箴言书注》2卷15题说“切勿浪费较多东西去做，用较少的东西，同样可以做好的事情。” 5.2 交叉验证数据集切分： 训练集，模型训练 验证集，模型选择 测试集，模型评估 简单交叉验证 S折交叉验证 留一交叉验证 6 泛化能力6.1 泛化误差generalization ability，泛化能力。 预测误差即为泛化误差，事实上泛化误差就是所学习到模型的期望风险。 6.2 泛化误差上届generalization error bound，泛化误差上届 7 生成模型与判别模型监督学习方法可分为生成方法和判别方法。 生产方法 生成方法 （generative approach）和生成模型（ generative model ）。由数据学习联合分布，求出条件概率分布作为预测的模型。之所以称为生成方法，是因为模型表示了给定的输入X产生输出Y的生成关系。典型生成模型：朴素贝叶斯法和隐马尔科夫模型。 辨别方法 辨别方法 （discriminative approach）和判别模型（ dissriminative model） 判别方法由数据直接学习决策函数$f(x)$或者条件概率分布作为预测的模型，判别方法关心的对给定的输入X，应该预测什么样的输出Y？典型的判别模型包括：K近邻法，感知机，决策树，逻辑斯蒂回归，最大熵模型，支持向量机等。 8 分类问题监督学习的核心问题。许多统计学习方法可用于分类，包括k近邻法，感知机，朴素贝叶斯，决策树，决策列表，逻辑斯蒂回归模型，支持向量机，提升方法，贝叶斯网络，神经网络等。 分类在于根据其特性将数据分门别类，在许多领域都有广泛的应用。 9 标注问题标注（tagging），分类问题的一个推广，也是更复杂结构预测问题的简单形式。标注问题在信息抽取、自然语言处理等领域被广泛应用，是这些领域的基本问题。例如自然语言处理中词性的标注（part of speech tagging）问题。 常见的标注统计学习方法有隐马尔科夫模型和条件随机场。 10 回归问题预测输入变量和输出变量之间的关系。回归问题的学习等价于函数拟合：选择一个函数曲线使其很好地拟合已知数据且很好地预测未知数据。 回归问题按照输入变量的个数，分为一元回归和多元回归；按照输入变量和输出变量关系的类型（即模型类型），分为线性回归和非线性回归。 回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以由著名的最小二乘法求解。 说明：本文因为涉及到不少公式，整理起来有点麻烦，所以没有在文中列出。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>统计学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Swagger常见问题汇总]]></title>
    <url>%2F2018%2F07%2F28%2Fswagger-notes%2F</url>
    <content type="text"><![CDATA[Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。Swagger让部署管理和使用功能强大的API变得更加简单。关于Swagger的入门教程，网上有很多，我这里就不再多言。本文总结几个在使用过程中遇到的几个问题。 两个界面显示问题看下图中被红框圈起来地方，有一些问题，其中：1）关于版本的选择，必须设置groupName，否则会有问题；2）需要把Lisense填上，否则右下角会有一个红色的“ERROR”。 代码如下： 12345678910111213141516171819@Beanpublic Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .groupName("V2") .select() .apis(RequestHandlerSelectors.basePackage("com.simt.dajiale.web.controller.agent.v2")) .paths(PathSelectors.any()) .build();&#125;private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("大家乐代理商接入API") .contact("SHIMU TECH") .description("V2版是当前正在使用的接口，如无特殊说明请按V2版接口进行开发测试！") .termsOfServiceUrl("") .version("2.0") .build();&#125; 生产环境不生效设置Spring boot中有个注解@ConditionalOnProperty，这个注解能够控制某个configuration是否生效。具体通过其两个属性name以及havingValue来实现，其中name用来从application.properties中读取某个属性值，如果该值为空，则返回false，如果值不为空，则将该值与havingValue指定的值进行比较，如果一样则返回true，否则返回false。如果返回值为false，则该configuration不生效，为true则生效。 1234@Configuration@ConditionalOnProperty(prefix = "swagger2",value = &#123;"enable"&#125;,havingValue = "true")@EnableSwagger2public class SwaggerConfiguration &#123;&#125;]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>swagger</tag>
        <tag>RESTful</tag>
        <tag>api</tag>
        <tag>问题总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[志言志语，智言智语]]></title>
    <url>%2F2018%2F07%2F27%2Fzyzy-restart-md%2F</url>
    <content type="text"><![CDATA[反省自己做事没什么长性，曾经弄了很多个博客，但都没能写出点什么来，这个github的也是！其实去年曾坚持写过一段时间，但后来因为没有找到好的评论功能插件，觉得这个博客不太完美，就渐渐荒废了，其实就算有评论功能，真正用到的时候也不会多，这只是懒人的借口罢了。 最近查资料的时候，发现有不少人在用gitalk，感觉效果还不错，于是也花时间折腾了一下，顺道把hexo和next也都升级到最新版本，打算重新开始写点东西。不过我这个人缺点太多，除了没有长性，还太随性，做事没有章法。比如想写的东西太多，写代码是工作，文史哲是爱好，炒股也是爱好，都想写，所以最后写的内容就乱七八糟，形不成体系，对自己的成长没多大促进作用，久而久之就会心生厌烦，直到放弃。 挑战因为之前教训实在是深刻，所以我必须有所改变。今后在这个博客上会有所侧重：一个技术博客，而且是侧重AI相关的技术博客。为什么会有这种想法？作为一个已经36岁的高龄程序员来说，自己的职业生涯非常惨淡，没有做过什么大项目，也没有写过什么特别成功的产品，大部分代码都成了垃圾无人问津，这是一件非常悲哀的事情。不过作为一个有追求的人，我不打算就这么悲哀下去，我打算做最后的抗争：从一个传统的Java程序员努力转型成AI相关的程序员。 对我来说，这是一个相当艰巨的目标，我很怀疑自己能走多远？我有很多理由怀疑自己，比如AI相关的机器学习、深度学习内容太过艰深，而自己智商不太够，再加上年龄偏大，就算能学个一知半解，想换一份相关性质的工作也绝非易事！拦路虎很多，不过这次我还是打算明知山有虎偏向虎山行了。毕竟到了我这个年纪，如果继续再像以前那么蹉跎，真的就要荒废了，现在立即行动说不定还有一丝希望。 计划具体来讲，这个github的技术博客，是用来帮助我进行AI转型的，当然因为现在还在从事传统Java开发（不科学，只是相对AI来讲），也会涉及相关内容，但不是重点。所以，今后我会在本站记录以下几个方面： 时光漫步 个人生活杂感，不会多，一年也写不了几篇，不写无病呻吟的内容； 编程语言 编程语言使用技巧，经验总结，主要包括Java和Python； 数据库 数据库理论，MYSQL使用技巧； 系统架构 主要是传统Java项目的系统设计和架构总结； 机器学习 机器学习相关内容，模型和算法。 深度学习 深度学习相关内容，模型和算法。 AI项目实战 机器学习和深度学习的项目总结。 AI行业观察 对AI行业相关的观察与思考。 因为本人特别热衷炒股，但是几年下来成绩也一般，所以对AI的学习和研究，最终会落在金融证券相关的专业领域，毕竟AI涉及的行业太多不可能都兼顾。 好了，不说太多废话了，现在开始属于我的一个新时代！]]></content>
      <categories>
        <category>自我管理</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>博客运营</tag>
        <tag>人工智能</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ML001.机器学习算法概览]]></title>
    <url>%2F2018%2F01%2F17%2Fai-ml-001-alg%2F</url>
    <content type="text"><![CDATA[Machine Learing学习笔记，主要参考Andrew Ng、李宏毅等大牛的课程和书籍。本文是001篇之机器学习算法概览，主要内容是对机器学习涉及到的各种学习模型和算法的简介。 1.算法概览本节不探讨算法的实现细节，只做总体的概览。机器学习的算法有很多，请看下面一张图，这张图来自台湾李宏毅教授机器学习课程PPT，很好的概括了机器学习的常见算法，可以作为一个学习路线图。 2.监督学习（Supervised Learning）首先要理解监督的到底是指什么？个人理解就是训练数据有标签，比如面积，价格，房间数等，预测也有目标性，即成交价格，这就是所谓的“监督”。 2.1 回归（Regression）NG课程里面举了一个预测房价的例子，还是比较容易理解的。如下图所示： 上图表示根据某一地区房屋历史交易数据，可以在图上标出面积和房价的点，根据这些历史数据，可以拟合出一条面积和价格之间的直线，或者曲线，进而预测房屋价格。 根据已有房屋历史交易数据（即所谓的“正确答案”）来来预测房屋交易价格（即更多“正确答案”），是典型的监督学习，而且是线性回归算法。这里要理解回归（Regression）是什么含义？简单来说，回归就意味着预测结果是连续的（Continuous）。 2.2 分类（Classification）如果预测结果是不连续的呢？这就属于分类问题，比如NG在课程中提到的癌症预测案例，如下图所示： 根据一个人身上肿块大小，预测肿瘤是良性的还是恶性的，即有没有得癌症？因为结果要么是得了癌症，要么是没得癌症，只有两个结果，即结果是不连续的，离散的。本实例只有两个结果，即良性和恶性，算是一个Binary Classification，当然有Multi-Class Classification,比如新闻分类，可以有很多种。 上述两个案例中，都是只有一个特征，实际问题中特征肯定不止一个，比如房间预测案例中房间数目，癌症预测案例病人年龄，都是有价值的特征。有一些算法可以处理多个甚至无限多特征，比如支持向量机（SVM），里面有 一个巧妙的数学技巧，能让计算机处理无限多个特征。 另外，监督学习中还有决策树，深度学习等，也属于分类算法，后面的课程笔记中再详细说明。 3.无监督学习（Unsupervised Learning）无监督学习肯定是相对监督学习而言，无监督学习不管是训练数据还是学习目标都不明确，没有任何标签（Unlabeled data），没有“正确答案”，只有一个数据集，算法自己从数据中学习出有价值的东西出来。最常见的应该是聚类算法，聚类算法应用很广泛，比如谷歌新闻分类，DNA微观数据集，大型计算机集群，推荐系统，天文数据分析等。 NG在课程中举了一个鸡尾酒宴问题（Cocktail Party Problem）的案例，即在一个嘈杂的环境中，如何根据两个麦克风输入的声音，提取出某一个人或者某个东西发出的声音，是一个无监督学习的例子。 4.其他除了无监督学习，图中还提到的几个算法，下面逐一简单说明之： Semi-supervised Learning，半监督学习是监督学习与无监督学习相结合的一种方法，同时使用未标记和有标记数据，来进行模式识别工作，能够提升学习效率； Transfer Learning，顾名思义就是就是把已学训练好的模型和参数，迁移到新的模型来帮助新模型训练数据集。 Reinforcement Learning 增强学习（或强化学习）是近年来机器学习和智能控制领域的主要方法之一。相比其他学习方法，增强学习更接近生物学习的本质，因此有望获得更高的智能，这一点在棋类游戏中已经得到体现，想必大火的阿尔法狗让你记忆犹新！ 5.另一种分类在网上看到过一篇机器学习的入门文章(《让我们从机器学习谈起》)，总结的也比较好，如下： 回归算法 入门算法，包括线性回归和逻辑回归。首先是线性回归，比如房价求解问题，寻找一条直线匹配所有数据，常用最小二乘法求解，但效率不高。数值计算用来提升计算的准确性和效率问题，例如梯度下降及牛顿法。其次是逻辑回归，与线性回归类似，但本质不同，线性回归处理的是数值问题，预测结果也为数值，逻辑回归属于分类算法，预测结果是离散分类。 神经网络，人工神经网络（ANN），基于大脑机理研究，在语音和视觉识别上效果好，BP算法诞生后发展进入新阶段。分解与整合是主要机理，但训练过程仍然困难，90年代后SVM算法取代了神经网络的地位。 SVM（支持向量机）支持向量机算法诞生于统计学界，是一种数学成分很浓的算法，是逻辑回归算法的强化，通过给与逻辑回归算法更严格的优化条件，通过高斯“核”获得比逻辑回归更好的分类界限，所谓“核”事实上就是一种特殊的函数，最典型的特征是可以将低纬空间映射到高纬空间。 聚类算法 没有标签，无监督算法的典型代表。计算种群中的距离，根据距离远近将数据划分为多个族群。 降维算法 无监督学习算法的一种，将数据从高纬降到低维，主要作用是压缩数据与提升机器学其他算法的效率。 推荐算法 电商网站用的最多，根据用户特征推荐可能感兴趣的东西。一个是基于物品内容的推荐，一个基于相似用户的推荐。 其他 高斯判别，朴素贝叶斯，决策树等 最后，奉上一张来自http://scikit-learn.org的神图，如下：]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ML000.机器学习入门]]></title>
    <url>%2F2018%2F01%2F02%2Fai-ml-000-introduction%2F</url>
    <content type="text"><![CDATA[Machine Learing学习笔记，主要参考Andrew Ng、李宏毅等大牛的课程和书籍。本文是000篇之机器学习入门，主要内容是机器学习的概念等基础知识。 AI今年实在太火，每天都能搞出大事情！从去年就计划学习相关知识，还尝试了几次，但每次看点入门知识就放弃了，因为内容确实有点难，感觉智商不太够用，/(ㄒoㄒ)/~~。不过形势所迫，不玩点有难度的早晚要沦落成diduan人口，被AI这玩意驱逐出地球。哎，为了全人类，还是破釜沉舟背水一战吧！ 最近找了很多资料，看了好几个公开课，比较流行的有大神Andrew NG在Coursera的机器学习课程，以及台湾李宏毅教授的课程，都比较适合初学者。我会参考这几个课程和其他参考书，结合自己的学习情况，整理一个大纲和笔记。 1 机器学习入门1.1机器学习被用来做什么？ 机器学习已经得到了很广泛的应用，比如谷狗，度娘的搜索技术，Facebook或Apple的图片分类程序，电子邮件垃圾邮件筛选器等等。Andrew Ng的课程中演示了一个自动飞行器，这让我们相信汽车自动驾驶时代很快就会到来。 1.2机器学习为什么越来越流行? 目前机器学习不只用于人工智能领域，它已经成为计算机一种新的能力(NewCapability），应用于很多方面，课程中提到了数据挖掘，自动化技术，理解人类思维了解人类大脑等等。下面是一个稍微详细点的分类，说明了机器学习涉及到领域： 模式识别 可以认为模式识别就是机器学习，模式识别是从工业界发展起来的概念，而机器学习则强调计算机学科。 数据挖掘 数据挖掘=机器学习+数据库。数据挖掘仅仅是一种思考方式，不必神话之。 统计学习 统计学的目的是通过学习更多的潜在模式和关联关系，来帮助人类深入理解数据。 统计学习近似于机器学习，与机器学习高度重合，统计学的发展促进了机器学习的大发展，但是两者侧重点不同。统计学习重点关注统计模型的发展优化，偏数学，而机器学习关注实际问题的解决，偏实际。 计算机视觉 计算机视觉 = 图像处理+机器学习。 语音识别 语音识别 = 语音处理+机器学习，即音频处理技术与机器学习的结合。 自然语言处理自然语言处理 = 文本处理 + 机器学习。自然语言处理是让机器理解人类语言的学科，词法分析，语义理解，机器学习等。 提到数据挖掘和大数据，有这样一种观点：成功的机器学习应用不是拥有最好的算法，而是拥有更多的数据。随着大数据概念的兴起，机器学习和大数据愈发耦合，可以说大数据是机器学习应用的最佳场景，二者互相依赖，共同发展。大数据的核心是利用数据的价值，机器学习则是利用数据价值的关键技术。 2 机器学习是什么？通俗来讲，机器学习就是教机器自己来完成任务，就这么简单。 机器学习目前不存在被广泛认可的定义，但有两个可以参考： 2.1 Arthur Samuel(1959)：在没有明确编程情况下，使计算机能够主动学习研究的领域【原文参考：Field of study that gives computers the ability to learn without being explicitly programmed.】。值得一提的是Arthur Samuel编写了最早的阿尔法狗，不过下的国际象棋； 2.2 Tom Mitchell(1998)：一个程序能从经验 E 中学习，解决任务 T，达到性能度量值 P，当且仅当有了经验 E 后，经过 P 评判，程序在处理 T 时的性能有所提升，这就是机器学习【原文参考：A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.】。 其中第二个定义正式一点，还押韵。具体到下棋的例子：经验E是程序自我练习的经验，而任务T就是下棋，性能度量值P就是它在与新的对手比赛时赢得比赛的概率。Ng课后测验里面有几题目测试对这个定义的理解，其中一道大意是：天气预报中，T，P，E分别是什么？ 在本小节中，Andrew NG提到了对各种工具应该采取何种态度？值得强调，既：拥有合适的工具很重要，但更重要的是：你要学会如何恰当地使用这些工具，会用与不会用的人之间存在着鸿沟。 3 几个容易混淆的概念初学者可能会被AI，ML和DL这三个概念搞糊涂，贴张让人神清气爽的图。 AI是最早的一个概念，发展一波三折： 从时间是上来讲，人工智能出现最早，机器学习和深度学习近些年才出现的。 从逻辑上来讲，人工智能是目标，机器学习和深度学习是实现手段。相对机器学习而言，深度学习听起来高大上，但概并不神秘，就是传统神经网络发展到了多隐藏层的情况。 4 如何学习机器学习因为是新手，这个问题暂时回答不了，不过随着时间的推移，我相信可以给出自己的建议。 首先是编程语言的选择： 构想一个合适的机器学习方法，从来都不是一个瀑布式的过程，相反你需要反复分析，在各色各样的机器学习算法中尝试不同版本的输入数据，这种探索方式非常适合Python。作为一门解释性高级语言，Python似乎就是专门为尝试不同事物而设计的。【机器学习系统设计 P2】]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>AI</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacOS下MySQL密码重置]]></title>
    <url>%2F2017%2F11%2F29%2Fmysql-reset-pwd%2F</url>
    <content type="text"><![CDATA[关于Mac上MySQL的密码重置，网上有很多说明，参照着试了一下，多有错误，整理备份之，供需要者参考。 1.关掉MySQL可以通过系统偏好设置进行关闭，或者使用命令行。在Mac OS X启动和停止MySQL服务的命令如下： //启动MySQL服务 sudo /usr/local/mysql/support-files/mysql.server start //停止MySQL服务 sudo /usr/local/mysql/support-files/mysql.server stop //重启MySQL服务 sudo /usr/local/mysql/support-files/mysql.server restart 2.Safe模式启动Mysql在终端中，进入Mysql目录，使用安全模式启动，禁止Mysql的验证功能，命令如下： cd /usr/local/mysql/bin/ sudo su ./mysqld_safe --skip-grant-tables &amp; 3.更新密码 上一步是安全模式启动，可以直接登录Mysql，执行如下命令： ./mysql 在MySQL命令行中执行更新密码的SQL： mysql&gt;FLUSH PRIVILEGES; mysql&gt;UPDATE mysql.user SET authentication_string=PASSWORD(&apos;123456&apos;) WHERE user=&apos;root&apos;; Query OK, 0 rows affected, 1 warning (0.00 sec) Rows matched: 1 Changed: 0 Warnings: 1 4.正常模式启动Mysql关闭Mysql后正常模式启动，可以用新设置的密码登录MySQL。 sh-3.2# sudo /usr/local/mysql/support-files/mysql.server stop Shutting down MySQL ... SUCCESS! [1]+ Done ./mysqld_safe --skip-grant-tables sh-3.2# sh-3.2# mysql -uroot -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 21 .....//提示信息省略 Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. 5.重设密码登录MySQL之后，在MySQL命令行中执行如下命令： mysql&gt; use mysql ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement. mysql&gt; SET PASSWORD = PASSWORD(&apos;123456&apos;); Query OK, 0 rows affected, 1 warning (0.00 sec) 操作完成。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二维码相关开发总结]]></title>
    <url>%2F2017%2F10%2F13%2Fqrcode-notes%2F</url>
    <content type="text"><![CDATA[最近在项目中，接触了一些二维码相关的功能，这里总结一二，备查。 二维码基础二维条码/二维码（2-dimensional bar code）是用某种特定的几何图形按一定规律在平面（二维方向上）分布的黑白相间的图形记录数据符号信息的；在代码编制上巧妙地利用构成计算机内部逻辑基础的“0”、“1”比特流的概念，使用若干个与二进制相对应的几何形体来表示文字数值信息，通过图象输入设备或光电扫描设备自动识读以实现信息自动处理：它具有条码技术的一些共性：每种码制有其特定的字符集；每个字符占有一定的宽度；具有一定的校验功能等。同时还具有对不同行的信息自动识别功能、及处理图形旋转变化等特点。 分类在许多种类的二维条码中，常用的码制有：DataMatrix，MaxiCode，Aztec，QRCode，Vericode，PDF417，Ultracode，Code49，Code16K等，QR码是1994年由日本Denso-Wave公司发明。QR来自英文QuickResponse的缩写，即快速反应的意思，源自发明者希望QR码可让其内容快速被解码。QR码最常见于日本、韩国，并为目前日本最流行的二维空间条码。 主要应用二维条码具有储存量大、保密性高、追踪性高、抗损性强、备援性大、成本便宜等特性，这些特性特别适用于表单、安全保密、追踪、证照、存货盘点、资料备援等方面。智能手机和平板电脑的普及应用催生了之前并不被看好的二维码应用，大家竞相投入大量资源进行技术研发。马化腾说：二维码是移动互联网入口。二维码的应用，似乎一夜之间渗透到我们生活的方方面面，地铁广告、报纸、火车票、飞机票、快餐店、电影院、团购网站以及各类商品外包装上。作为物联网浪潮产业中的一个环节，二维码的应用从未这么受到关注，有专家甚至预测，将在两三年内形成上千亿的市场空间。 二维码的应用的有主读和被读的概念。国外，二维码的平台式服务指的是有一个平台来供你生成二维码，并在那后面附上图片、文字、视频等各种各样的信息。本质上，二维码的内容是指向一个地址。所以二维码平台式服务属于被读的领域。 二维码的生成可选择的API二维码的生成，网上有很多例子，各种程序版本的都有，这里只提一下Java版本的注意事项。Java版本的有两种选择，分别是Zxing和QRcode。 ZXing用Java实现的多种格式的1D/2D条码图像处理库，Zxing库的主要部分支持以下几个功能：核心代码的使用、适用于J2SE客户端的版本、适用于Android客户端的版本（即BarcodeScanner）、Android的集成（通过Intent支持和BarcodeScanner的集成）等。ZXing处理库可以生成和识别QRCode码。 QRCode码，是由日本Denso公司于1994年9月研制的一种矩阵二维码符号。 个人推荐如果桌面或Web应用，采用Denso公司的QRCode库，Android应用采用ZXing处理库。 其中网上提供的QRCode的Jar包，开发的时候找了好几个才找对，官网下载的那个只有生成没有解析，而网上的例子大都是带着解析方法的，所以用集成了解析API的Jar包。 二维码的大小二维码有大小（version）,version越大存储信息越多，生成的二维码图片也越大越复杂，在实际使用过程中，虽然可以使用更大的级别，但是如果图片太大，通过微信发送图片的时候，在微信中点击图片，不能被微信作为二维码识别，使用不方便。原因如下：二维码所能包含的字符信息量是由QrcodeVersion的设置值来决定的。将QrcodeVersion设置到20的时候，就已经可以容乃到300多个字节。不过修改了QrcodeVersion的值，解决的仅仅是字符集容量的问题，这样生成的图片可能无法解码。可是把字符容量控制在128个以内的时候，就可以正常的解码。生成的二维码图片的大小是会根据所压缩的信息内容而变化的，网上提供的例子是通过new BufferedImage(139, 139, BufferedImage.TYPE_INT_RGB);来创建图像对象的，默认的情况下图片的大小是139139，这个大小是比较适合QrcodeVersion为7的情况。将图片的大小设置到300300就可以很好的支持QrcodeVersion为20的情况，并且可以正常的解码。 二维码名片相关vCard 规范容许公开交换个人数据交换 (Personal Data Interchange PDI) 信息，在传统纸质商业名片可找到这些信息。规范定义电子名片（或叫vCard）的格式。 vCard 规范可作为各种应用或系统之间的交换格式。定义的格式与传送的方法无关。传送交换可能是文件系统，点对点交换的公共电话网络，以有线网络或无线传送的方式。用户能在互联网上直接利用vCard。电子邮件能转发在vCard中人信息。网页上很多用户填写的表格可自动使用vCard。 在实际开发过程中，需要注意的几点： 个人名片信息量不是很大，生成二维码名片的大小可以为12，这个大小能包含基本的信息，生成的二维码也不会太复杂，在微信中可以很好的被识别。 自定义字段，虽然信息可以写入，但是微信扫码识别不出来。]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>Qrcode</tag>
        <tag>二维码</tag>
        <tag>Vcard</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bat脚本的几点经验总结]]></title>
    <url>%2F2017%2F07%2F06%2Fwin-bat-about%2F</url>
    <content type="text"><![CDATA[最近有个小项目需要在Window环境下部署，需要写一个bat启动脚本，但是因为对bat脚本语法不太清楚，找了个之前用的模版，算是能用了。期间碰到几个小问题，记录一下： 简单语法说明123456789101112131415161718if exist "%JAVA_HOME%" goto okHomeecho The JAVA_HOME environment variable is not defined correctlygoto end:okHomeif exist "%JAVA_HOME%\bin\java.exe" goto runecho The java.exe is not availablegoto end:runset CLASSPATH=.for %%i in (.\lib\*.jar) do call cpappend.bat %%i%JAVA_HOME%\bin\java.exe -classpath %CLASSPATH% com.xxx.JxzkMain 192.xx.xx.xxx 99xx 99xx 90xx1&gt;&gt;/var/log/xxx-data.out2&gt;&gt;/var/log/xxx-data.alarms &amp;:end 说明：FOR %%variable IN (set) DO command [command-parameters]，%%i应该是代表了”.\lib*.jar”中的每一个jar包 for %%i in (“.\lib*.jar”) 应该是遍历”.\lib*.jar”中的每一个jar包,同时用%%i来存储名称call setenv.bat %%i 应该是把%%i当参数调用setenv.batset cp=%cp%;%1 应该是把每一个%%i和%cp%拼接起来，再次赋值给%cp%变量 set cp=for %%i in (“.\lib*.jar”) do call cpappend.bat %%i，应该是遍历lib包下的每一个jar包，同时把jar包名称用;拼接成起来赋值给cp变量 java -cp %cp% com.test.DoMain 这个是执行Java main方法1&gt;&gt;/var/log/xxx-data.out 输出日志信息2&gt;&gt;/var/log/xxx-data.alarms &amp; 输出告警信息 让命令行窗口处于显示等待状态 pause 环境变量中的空格脚本写好之后，在自己的开发机器上运行正常，可以把应用拉起来，但是放到生产环境上，却报了一个异常： ‘C:\Program’ 不是内部或外部命令，也不是可运行的程序或批处理文件。看着好像是Java的安装目录有问题，以为是环境变量配置的不对，重新配置了一遍，还是不行！因为生产Java安装在了C:\Program Files下，中间有个空格，可能会有问题，网上查了一下，果然！ 如果本机环境变量的设置：java_home = C:\Program Files\Java\jdk1.8.0_131*.bat中的命令格式：%java_home%\bin\java 或者 C:\Program Files\Java\jdk1.8.0_131\bin\java运行这个.bat发现提示错误： “c:\Program” 不是内部或外部命令，检查了下，发现路径没有填写错误因此本人推断DOS中可能无法识别路径中有空格的情况，因此就google了一把还发现真的是这样。解决空格问题一共有两种办法： 一个是想办法在环境变量设置的时候用特殊字符给他替换掉：C:\PROGRA~1\Java\jdk1.8.0_131 另外一个就是在写代码的时候用双引号给有空格的路径给它引起来， “C:\Program Files”\Java\jdk1.8.0_131\bin\java需要注意的是，在环境变量中使用C:\PROGRA~1\，在bat中用%JAVA_HOME%引用是没有效果的，只有直接写在bat中才行，即：set JAVA_HOME=C:\PROGRA~1\Java\jdk1.8.0_131]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Bat</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JWT介绍及Java实现JJWT使用总结]]></title>
    <url>%2F2017%2F06%2F14%2Fjson-web-tokens-notes%2F</url>
    <content type="text"><![CDATA[JWT介绍Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC7519)，该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。 认证方案Session认证在谈论JWT之前，我们先看一下传统的session认证方案：http协议本身是一种无状态的协议，这意味着用户向应用提供用户名和密码来进行用户认证，那么下一次请求时，用户还要再一次进行用户认证才行，因为根据http协议，我们并不能知道是哪个用户发出的请求，所以为了让我们的应用能识别是哪个用户发出的请求，我们只能在服务器存储一份用户登录的信息，这份登录信息会在响应时传递给浏览器，告诉其保存为cookie,以便下次请求时发送给我们的应用，这样我们的应用就能识别请求来自哪个用户了,这就是传统的基于session认证。但是这种基于session的认证使应用本身很难得到扩展，随着不同客户端用户的增加，独立的服务器已无法承载更多的用户，而这时候基于session认证应用的问题就会暴露出来。 基于session认证所显露的问题: Session: 每个用户经过我们的应用认证之后，我们的应用都要在服务端做一次记录，以方便用户下次请求的鉴别，通常而言session都是保存在内存中，而随着认证用户的增多，服务端的开销会明显增大。 扩展性: 用户认证之后，服务端做认证记录，如果认证的记录被保存在内存中的话，这意味着用户下次请求还必须要请求在这台服务器上,这样才能拿到授权的资源，这样在分布式的应用上，相应的限制了负载均衡器的能力。这也意味着限制了应用的扩展能力。 CSRF: 因为是基于cookie来进行用户识别的, cookie如果被截获，用户就会很容易受到跨站请求伪造的攻击。 基于token的鉴权机制基于token的鉴权机制类似于http协议也是无状态的，它不需要在服务端去保留用户的认证信息或者会话信息。这就意味着基于token认证机制的应用不需要去考虑用户在哪一台服务器登录了，这就为应用的扩展提供了便利。流程上是这样的： 用户使用用户名密码来请求服务器 服务器进行验证用户的信息 服务器通过验证发送给用户一个token 客户端存储token，并在每次请求时附送上这个token值 服务端验证token值，并返回数据 这个token必须要在每次请求时传递给服务端，它应该保存在请求头里， 另外，服务端要支持CORS(跨来源资源共享)策略，一般我们在服务端这么做就可以了Access-Control-Allow-Origin: *。 JWTJWT长什么样？JWT是由三段信息构成的，如下: eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJKb2UifQ.ipevRNuRP6HflG8cFKnmUPtypruRC4fb1DWtoLL62SY headerjwt的头部承载两部分信息：声明类型(这里是jwt)和声明加密的算法（通常直接使用 HMAC SHA256），完整的头部就像下面这样的JSON：1234&#123; 'typ': 'JWT', 'alg': 'HS256'&#125; 然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分：eyJhbGciOiJIUzI1NiJ9 playload载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分:即标准中注册的声明，公共的声明，私有的声明标准中注册的声明 (建议但不强制使用) ： iss: jwt签发者 sub: jwt所面向的用户 aud: 接收jwt的一方 exp: jwt的过期时间，这个过期时间必须要大于签发时间 nbf: 定义在什么时间之前，该jwt都是不可用的. iat: jwt的签发时间 jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。公共的声明 ：公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.私有的声明 ：私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。如下：12345&#123; "sub": "1111111", "name": "2222222222", "admin": true&#125; signaturejwt的第三部分是一个签证信息，这个签证信息由三部分组成：header (base64后的),payload (base64后的),secret。这个部分需要base64加密后的header和base64加密后的payload使用.连接组成的字符串，然后通过header中声明的加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分。 JWT的Java实现JJWTJWT现在已经算得上流行了，各种语言都有了不同版本的实现，下面简单说明一下Java版本的实现之一JJWT。 Maven依赖：12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.7.0&lt;/version&gt;&lt;/dependency&gt; 生成Token：12345Key key = MacProvider.generateKey();String compactJws = Jwts.builder() .setSubject("Joe") .signWith(SignatureAlgorithm.HS512, key) .compact(); 解析Token：123456try &#123; Jwts.parser().setSigningKey(key).parseClaimsJws(compactJws); //OK, we can trust this JWT,正常解析则表示Token有效&#125; catch (SignatureException e) &#123; //don't trust the JWT!，不能解析则表示Token非法，拒绝请求&#125; 最初了解JWT的时候，对其如何验证请求带上来的Token有些疑问，这里在对签名进行加密的时候，是一个固定的Key，保存在服务端，不能泄露，否则就失去了意义！123456public static SecretKey generalKey()&#123; String stringKey = JWT_SECRET;//固定值，比如123456 byte[] encodedKey = Base64.decodeBase64(stringKey); SecretKey key = new SecretKeySpec(encodedKey, 0, encodedKey.length, "AES"); return key;&#125;]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
        <tag>JWT</tag>
        <tag>JJWT</tag>
        <tag>开源软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之观察者模式]]></title>
    <url>%2F2017%2F05%2F11%2Fdesign-pattern-observer%2F</url>
    <content type="text"><![CDATA[定义观察者模式，又可以称之为发布-订阅模式。观察者，顾名思义，就是一个监听者，一旦被观察/监听的目标发生的情况，就会被监听者发现，这么想来目标发生情况到观察者知道情况，其实是由目标把情况通知到观察者的。观察者模式多用于实现订阅功能的场景，例如微博的订阅，当我们订阅了某个人的微博账号，当这个人发布了新的消息，就会通知我们。下面的类图说明的比较清楚： 角色说明 抽象被观察者角色：把所有对观察者对象的引用保存在一个集合中，每个被观察者角色都可以有任意数量的观察者。被观察者提供一个接口，可以增加和删除观察者角色。一般用一个抽象类和接口来实现。 抽象观察者角色：为所有具体的观察者定义一个接口，在得到主题的通知时更新自己。 具体被观察者角色：在被观察者内部状态改变时，给所有登记过的观察者发出通知。具体被观察者角色通常用一个子类实现。 具体观察者角色：该角色实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题的状态相协调。通常用一个子类实现。如果需要，具体观察者角色可以保存一个指向具体主题角色的引用。 适用场景 当一个抽象模型有两个方面, 其中一个方面依赖于另一方面。将这二者封装在独立的对象中以使它们可以各自独立地改变和复用。 当对一个对象的改变需要同时改变其它对象, 而不知道具体有多少对象有待改变。 当一个对象必须通知其它对象，而它又不能假定其它对象是谁（换言之,你不希望这些对象是紧密耦合的）。 简单实例观察者模式还是比较容易理解的，在网上看到了一个运钞车的例子，觉得挺好玩，我也瞎编了一个场景：一个姑娘失恋了，在微博上发了条微博，几个潜在的追求者看到了微博，纷纷出动。 抽象的观察者12345package com.zyzy.obs;public interface Watcher &#123; public void update(); &#125; 抽象的被观察者，声明了三个方法，通知观察者方法，增删观察者方法。123456789package com.zyzy.obs;public interface Watched &#123; public void addWatcher(Watcher watcher); public void removeWatcher(Watcher watcher); public void notifyWatchers(); &#125; 观察者之屌丝BOY12345678package com.zyzy.obs;public class DsBoy implements Watcher &#123; @Override public void update() &#123; System.out.println("屌丝：女神失恋啦，我要去表白，本屌将献诗一首！"); &#125;&#125; 观察者之二代BOY123456789package com.zyzy.obs;public class FedBoy implements Watcher &#123; @Override public void update() &#123; System.out.println("二代：妹妹，不要伤心，哥哥这里啥都有，过来跟着哥耍吧！"); &#125;&#125; 观察者之暖男BOY123456789package com.zyzy.obs;public class JjBoy implements Watcher&#123; @Override public void update() &#123; System.out.println("暖男：不要伤心，我是居家暖男，来家里给你做饭吃！"); &#125;&#125; 具体的被观察者：Girl123456789101112131415161718192021222324252627package com.zyzy.obs;import java.util.ArrayList;import java.util.List;public class BfmGirl implements Watched &#123; private List&lt;Watcher&gt; list = new ArrayList&lt;Watcher&gt;(); @Override public void addWatcher(Watcher watcher) &#123; list.add(watcher); &#125; @Override public void removeWatcher(Watcher watcher) &#123; list.remove(watcher); &#125; @Override public void notifyWatchers() &#123; System.out.println("Girl：哇哇哇，我滴男盆友跟闺蜜跑了，咋办？咋办？咋办？在线等。。。"); for(Watcher w:list)&#123; w.update(); &#125; &#125;&#125; 测试类1234567891011121314151617package com.zyzy.obs;public class ObsTest &#123; public static void main(String[] args) &#123; BfmGirl girl = new BfmGirl(); DsBoy dsBoy = new DsBoy(); FedBoy fedBoy = new FedBoy(); JjBoy jjBoy = new JjBoy(); girl.addWatcher(dsBoy); girl.addWatcher(fedBoy); girl.addWatcher(jjBoy); girl.notifyWatchers(); &#125;&#125; 运行测试类输出： Girl：哇哇哇，我滴男盆友跟闺蜜跑了，咋办？咋办？咋办？在线等。。。屌丝：女神失恋啦，我要去表白，本屌将献诗一首！二代：妹妹，不要伤心，哥哥这里啥都有，过来跟着哥耍吧！暖男：不要伤心，我是居家暖男，来家里给你做饭吃！ 要点总结模式关键观察者模式最主要的设计思想是什么呢？第一是针对观察者与被观察者分别定义接口，有利于分别进行扩展。关键点在被观察者的实现中：1）定义观察者集合，并定义针对集合的添加、删除操作，用于增加、删除订阅者（观察者）；2）定义通知方法，用于将新情况通知给观察者用户（订阅者用户） 和桥接模式的区别观察者模式定义的是一对多的依赖关系，一个被观察者可以拥有多个观察者，并且通过接口对观察者与被观察者进行逻辑解耦，降低二者的直接耦合。这种模式与桥接模式有点类似的感觉。桥接模式也是拥有双方，同样是使用接口（抽象类）的方式进行解耦，使双方能够无限扩展而互不影响，不过二者还是有者明显的区别： 主要就是使用场景不同，桥接模式主要用于实现抽象与实现的解耦，主要目的也正是如此，为了双方的自由扩展而进行解耦，这是一种多对多的场景。观察者模式侧重于另一方面的解耦，侧重于监听方面，侧重于一对多的情况，侧重于一方发生情况，多方能获得这个情况的场景。 另一方面就是编码方面的不同，在观察者模式中存在许多独有的内容，如观察者集合的操作，通知的发送与接收，而在桥接模式中只是简单的接口引用。 推还是拉？ 小实例中没有关于数据和状态的变化通知，只是简单通知到各个观察者，告诉他们被观察者有行动。观察者模式在关于目标角色、观察者角色通信的具体实现中，有两个版本： 一种情况便是目标角色在发生变化后，仅仅告诉观察者角色“我变化了”，观察者角色如果想要知道具体的变化细节，则就要自己从目标角色的接口中得到。这种模式被很形象的称为：拉模式——就是说变化的信息是观察者角色主动从目标角色中“拉”出来的。 还有一种方法，那就是我目标角色“服务一条龙”，通知你发生变化的同时，通过一个参数将变化的细节传递到观察者角色中去。这就是“推模式”——管你要不要，先给你啦。上述两种模式如何选择，取决于系统实际需求。如果目标角色比较复杂，并且观察者角色进行更新时必须得到一些具体变化的信息，则“推模式”比较合适。如果目标角色比较简单，则“拉模式”就很合适。 实际案例观察者模式应用很广泛，下面介绍几个常见的场景。（未完待续）]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>观察者模式</tag>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL常用运维命令汇总]]></title>
    <url>%2F2017%2F05%2F09%2Fmysql-om-notes%2F</url>
    <content type="text"><![CDATA[常用命令查询当前版本12345678//在终端下：mysql -V[root@simu10 ~]# mysql -Vmysql Ver 14.14 Distrib 5.1.71, for redhat-linux-gnu (x86_64) using readline 5.1//在help里面查找[root@simu10 ~]# mysql --help | grep Distribmysql Ver 14.14 Distrib 5.1.71, for redhat-linux-gnu (x86_64) using readline 5.1//使用mysql的函数:select version(); 查看my.cnf位置12345[root@db42 etc]# which mysqld/usr/sbin/mysqld[root@db42 etc]# /usr/sbin/mysqld --verbose --help |grep -A 1 'Default options';Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf 状态检查（SHOW查看状态）123456789101112131415161718192021222324252627282930313233343536373839//显示状态信息mysql&gt; SHOW [SESSION|GLOBAL] STATUS LIKE '%Status_name%';//session（默认）：取出当前窗口的执行//global：从mysql启动到现在//（a）查看查询次数（插入次数com_insert、修改次数com_insert、删除次数com_delete）mysql&gt; SHOW STATUS LIKE 'com_select';//（b）查看连接数(登录次数)mysql&gt; SHOW STATUS LIKE 'connections';//（c）数据库运行时间mysql&gt; SHOW STATUS LIKE 'uptime';//（d）查看慢查询次数mysql&gt; SHOW STATUS LIKE 'slow_queries';//（e）查看索引使用的情况：mysql&gt; SHOW STATUS LIKE 'handler_read%';//handler_read_key：这个值越高越好，越高表示使用索引查询到的次数。//handler_read_rnd_next：这个值越高，说明查询低效。//查询系统参数设置mysql&gt; SHOW VARIABLES LIKE '%Variables_name%';//显示InnoDB存储引擎的状态mysql&gt; SHOW ENGINE INNODB STATUS;//EXPLAIN分析查询mysql&gt; EXPLAIN SELECT column_name FROM table_name;//开启profile。查看当前SQL执行时间mysql&gt; SET PROFILING=ON;mysql&gt; SHOW profiles;//查看所有用户的当前连接。包括执行状态、是否锁表等mysql&gt; SHOW processlist;//PROCEDURE ANALYSE()取得建议//通过分析select查询结果对现有的表的每一列给出优化的建议mysql&gt; SELECT column_name FROM table_name PROCEDURE ANALYSE();//OPTIMIZE TABLE回收闲置的数据库空间mysql&gt; OPTIMIZE TABLE table_name;//对于MyISAM表，当表上的数据行被删除时，所占据的磁盘空间并没有立即被回收，使用命令后这些空间将被回收，并且对磁盘上的数据行进行重排（注意：是磁盘上，而非数据库）。//对于InnoDB表，OPTIMIZE TABLE被映射到ALTER TABLE上，这会重建表。重建操作能更新索引统计数据并释放成簇索引中的未使用的空间。//只需在批量删除数据行之后，或定期（每周一次或每月一次）进行一次数据表优化操作即可，只对那些特定的表运行。//REPAIR TABLE修复被破坏的表mysql&gt; REPAIR TABLE table_name;//CHECK TABLE检查表是否有错误mysql&gt; CHECK TABLE table_name; MYSQL 慢查询设置123456789101112//查看慢查询参数，默认关闭（OFF）mysql&gt; show variables like '%slow_query_log%';//设置慢查询开关（ON）mysql&gt; set global slow_query_log=1;//查询慢查询参数（慢的标准，默认10s）mysql&gt; show variables like 'long_query_time%';//设置慢查询参数（设置之后，需要重连才能在命令行看到更改后的值）mysql&gt; set global long_query_time=5;//查看慢查询日志输出方式（FILE OR TABLE）mysql&gt; show variables like '%log_output%';//查询出现过errors或warnings的表（5.7以上版本可用）：SELECT query,db,exec_count,errors,warnings,last_seen FROM sys.statements_with_errors_or_warnings ORDER BY errors DESC LIMIT 20; explain查询sql执行计划，各列含义： table：表名；type：连接的类型 -const：主键、索引； -eq_reg：主键、索引的范围查找； -ref：连接的查找（join） -range：索引的范围查找； -index：索引的扫描； -all：全表扫描；possible_keys：可能用到的索引；key：实际使用的索引；key_len：索引的长度，越短越好；ref：索引的哪一列被使用了，常数较好；rows：mysql认为必须检查的用来返回请求数据的行数；extra：using filesort、using temporary（常出现在使用order by时）时需要优化。 -Using filesort 额外排序。看到这个的时候，查询就需要优化了 -Using temporary 使用了临时表。看到这个的时候，也需要优化 大小写相关MySQL在Linux下数据库名、表名、列名、别名大小写规则是这样的：1）数据库名与表名是严格区分大小写的；2）表的别名是严格区分大小写的；3）列名与列的别名在所有的情况下均是忽略大小写的；4）变量名也是严格区分大小写的；5）MySQL在Windows下都不区分大小写，但是在Linux下默认是区分大小写的。6）如果想在查询时区分字段值的大小写，则字段值需要设置BINARY属性，设置的方法有多种。所以在不同操作系统中为了能使程序和数据库都能正常运行，最好的办法是在设计表的时候都转为小写！ 修改mysql为不区分大小写设置：1234567[root@test-huanqiu ~]# mysqladmin -uroot -p shutdown //以安全模式关闭数据库[root@test-huanqiu ~]# cat /etc/my.cnf //添加下面一行设置.....[mysqld]lower_case_table_names=1.....[root@test-huanqiu ~]# /etc/init.d/mysql start //启动mysql]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSON相关总结]]></title>
    <url>%2F2017%2F05%2F08%2Fjs-json-notes%2F</url>
    <content type="text"><![CDATA[基础知识JSON的全称是”JavaScript Object Notation”，意思是JavaScript对象表示法，它是一种基于文本，独立于语言的轻量级数据交换格式。和XML相比JSON有什么优点呢？因为XML虽然可以作为跨平台的数据交换格式，但是在JS(JavaScript的简写)中处理XML非常不方便，同时XML标记比数据多，增加了交换产生的流量，而JSON没有附加的任何标记，在JS中可作为对象处理，所以我们更倾向于选择JSON来交换数据。 JS中处理JSON数据JSON有两种表示结构，对象和数组。对象结构以”{”大括号开始，以”}”大括号结束。中间部分由0或多个以”，”分隔的”key(关键字)/value(值)”对构成，关键字和值之间以”：”分隔，数组或对象的值可以是简单值也可以是复合值。简单值包括字符串、数值（必须是十进制标识）、布尔值和Null，其中（NaN,Infinity,-Infinity和undefined都会被转换为null)。复合值包括符合json格式的数组或对象需要注意的是，数组或对象的最后一个成员后面不能加逗号，数组或对象之中的字符串必须使用双引号，不能使用单引号，对象的成员名称必须使用双引号。空数组或者空对象都是合格的json值，Null也是一个合格的json值。常见操作如下： 定义JSON对象 从JSON对象中读数据 向JSON对象中写数据（增加） 修改JSON对象中的数据 删除JSON对象中的数据 遍历JSON对象中的数据 判断是否有某属性123obj["key"] != undefined //这种有缺陷，如果这个key定义了，并且就是很2的赋值为undefined，那么这句就会出问题了。!("key" in obj)obj.hasOwnProperty("key") ES5中添加了json对象，其包含两个方法：JSON.stringify()和JSON.parse()，其中stringify将一个值转换为json格式的字符串，该字符串可以被JSON.parse()解析。parse()用来将json格式的字符串转换为对象。如果该json字符串不符合json格式，则会报错。 Java服务端处理JSON数据json-libjson-lib最开始的也是应用最广泛的json解析工具，json-lib 不好的地方确实是依赖于很多第三方包，包括commons-beanutils.jar，commons-collections-3.2.jar，commons-lang-2.6.jar，commons-logging-1.1.1.jar，ezmorph-1.0.6.jar，对于复杂类型的转换，json-lib对于json转换成bean还有缺陷，比如一个类里面会出现另一个类的list或者map集合，json-lib从json到bean的转换就会出现问题。json-lib在功能和性能上面都不能满足现在互联网化的需求。 开源的Jackson相比json-lib框架，Jackson所依赖的jar包较少，简单易用并且性能也要相对高些。而且Jackson社区相对比较活跃，更新速度也比较快。Jackson对于复杂类型的json转换bean会出现问题，一些集合Map，List的转换出现问题。Jackson对于复杂类型的bean转换Json，转换的json格式不是标准的Json格式 Google的GsonGson是目前功能最全的Json解析神器，Gson当初是为因应Google公司内部需求而由Google自行研发而来，但自从在2008年五月公开发布第一版后已被许多公司或用户应用。Gson的应用主要为toJson与fromJson两个转换函数，无依赖，不需要例外额外的jar，能够直接跑在JDK上。而在使用这种对象转换之前需先创建好对象的类型以及其成员才能成功的将JSON字符串成功转换成相对应的对象。类里面只要有get和set方法，Gson完全可以将复杂类型的json到bean或bean到json的转换，是JSON解析的神器。Gson在功能上面无可挑剔，但是性能上面比FastJson有所差距。 阿里巴巴的FastJsonFastjson是一个Java语言编写的高性能的JSON处理器,由阿里巴巴公司开发。无依赖，不需要例外额外的jar，能够直接跑在JDK上。FastJson在复杂类型的Bean转换Json上会出现一些问题，可能会出现引用的类型，导致Json转换出错，需要制定引用。FastJson采用独创的算法，将parse的速度提升到极致，超过所有json库。 综合点评综上4种Json技术的比较，在项目选型的时候可以使用Google的Gson和阿里巴巴的FastJson两种并行使用，如果只是功能要求，没有性能要求，可以使用google的Gson，如果有性能上面的要求可以使用Gson将bean转换json确保数据的正确，使用FastJson将Json转换Bean 问题总结命名不规则的JavaBean转换之前遇到过一个旧工程改造的项目，接口返回内容不变，因为老接口中JSON数据库属性名称千奇百怪，有的全大些，有的是驼峰，有的是首字母大写等等，用GSON可以解决这一问题。 GSON自动可以过滤空的属性GSON可以自动过滤掉空的属性，但是有时前端需要的接口信息不需要这样做，可以采用如下方案。1Gson gson = new GsonBuilder().serializeNulls().create();]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>Json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java枚举使用总结]]></title>
    <url>%2F2017%2F05%2F06%2Fjava-enum-notes%2F</url>
    <content type="text"><![CDATA[题记：本文为工作十年回顾总结系列之Java语言之枚举篇，主要内容为《Thinking in Java 》第四版和《Effective Java》第二版的阅读笔记，网上流传的最佳实践，以及个人工作总结的杂糅汇总，作为个人知识库存档备份，文中引用不再一一说明。 基础语法enum:可以将一组具名的值的有限集合创建为一种新的类型，这些具名的值可以作为常规程序组件使用。尽管enum看起来像是一种数据类型，但这个关键字只是为enum生成对应的类型时产生了某些编译器行为，所以在很大程度上，可以将enum当作其他任何类来处理。 常用方法事实上enum确实是类，并且具有自己的方法。比如： toString()，某个enum实例的名字； ordinal()，某个特定常量的声明顺序； static values()，按照常量的声明顺序，产生由这些常量构成的数组； getDeclaringClass()方法，返回所属的enum类。 equals()和hashCode()，可以用==比较 compareTo()，实现了Comparable接口，所以有该方法 name()和toString()功能相同 valueOf() enum可以添加方法，如果定义自己的方法，必须先定义enum实例序列，而且实例序列最后添加一个分号，再定义方法。enum的values()是由编译器添加的static方法，如果将enum向上转型为Enum，那么values()方法就访问不到了。不过在Class中有一个getEnumConstants()方法，可以获取所有enum实例。 如何组织枚举？所有enum都继承自java.lang.Enum类。由于Java不支持多重继承，所以你的enum不能再继承其他类。但是可以同时实现一个或多个接口。虽然无法从enum继承子类（即无法扩展enum中元素，或者使用子类将enum元素分类），可能方案有： 在一个接口内部，创建实现该接口的枚举，以此将元素进行分组，可以达到将枚举元素分类组织的目的。 如果类型太多，则可以创建一个新的enum，然后用其实例包装接口中的每一个enum类。 一个enum嵌套在另一个enum中。-EnumSet Set是一种集合，只能向其中添加不重复的对象，而enum也要求其成员都是唯一的，所以enum看起来也有集合的行为。EnumSet是通过enum创建了一种替代品，替代基于传统的位标志，这种标志可以用来表示某种开关信息。EnumSet非常快速高效，优点是在说明一个二进制位是否存在时，具有更好的表达能力，并且无需担心性能。 EnumMapEnumMap是一种特殊的Map,它要求其中的键（key），必须来自一个enum，其他操作与一般Map差不多。enum的每个实例作为一个键，总是存在的。但是如果没有为这个键调用put()方法来存入响应的值，其对应值就是null。与常量相关的方法相比，EnumMap有一个优点，允许改变值对象，而常量相关的方法在编译期就被固定了。 enum用途在switch语句中使用enum有一个特别有用的特性，可以在switch语句中使用。由于switch是要在有限的可能值集合中进行选择，因此它与enum是绝佳的选择。而且在case语句中可以不用enum类型修饰enum实例。 随机选取从enum随机选取，可以利用泛型简化，使这个工作一般化。enum可以消除很多重复代码，重复会制造麻烦，因此消除重复总是有意的。 常量相关的方法enum有一个非常有趣的特性，允许程序员为enum实例编写方法，从而为每个enum实例赋予各自不同的行为。要实现常量相关的方法，需要为enum定义一个或多个abstract方法，然后为每个enum实例实现该抽象方法。 使用enum的职责链在职责链（Chain Of Responsibility）设计模式中，程序员以多种不同的方式来解决一个问题，然后将他们链接在一起，当一个请求到来时，它遍历这个链，直到链中的某个解决方案能够处理该请求。通过常量相关的方法，可以很容易实现一个简单的职责链，比如邮局确认死信的过程。 使用enum的状态机枚举类型非常适合来创建状态机，一个状态机可以具有有限定个特定的状态，它通常根据输入，从一个状态转移到另一个状态，不过也可能存在瞬时状态(transient states),而一旦任务执行结束，状态机会立即离开瞬时状态。由于enum对其实例有严格限制，非常适合用来表现不同的状态和输入。一般而言，每个状态都具有一些相关的输出。比如自动售货机。 多路分发当处理多种交互类型时，程序会变得相当复杂。比如一个系统要分析和执行数学表达，a.plus(b)时，你并不知道a或b的确切类型，如何正确交互呢？Java只支持单路分发，也就是说如果要执行操作包含了不止一个类型未知的对象时，那么Java的动态绑定行为只能处理其中一个类型。解决上述问题的方法是多路分发，而实现多路分发有下面几种途径： 常规方法 使用enum分发 使用常量相关的方法 使用EnumMap分发 使用二维数组 Effective java 中几条使用建议第30条：用enum代替int常量第31条：用实例域代替序数永远不要根据枚举的序数导出与它关联的值，而是将它保存在一个实例域中。大多数程序员不需要用ordinal方法，它是用于设计EnumSet和EnumMap这种基于枚举的通用数据结构的。 第32条：用EnumSet代替位域第33条：用EnumMap代替序数索引第34条：用接口模拟可伸缩的枚举虽然无法编写可扩展的枚举类型，但是可以通过编写接口以及实现该接口的基础枚举类型，对它进行模拟。 最后的总结总结虽然枚举类型本身不复杂，是一个小功能，但是它可以优雅而干净地解决问题。优雅和清晰很重要，正是它们区别了成功的解决方案与失败的解决方案，而失败的解决方案就是因为其他人无法理解它。]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java编程思想</tag>
        <tag>笔记</tag>
        <tag>十年总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux项目部署总结]]></title>
    <url>%2F2017%2F04%2F18%2Flinux-project-deployment-record%2F</url>
    <content type="text"><![CDATA[Mysql相关Mysql采用RPM的方式安装，安装过程碰到了几个问题。 启动用户的问题第一个问题是执行mysqld -initialize的时候，报如下错误：[ERROR] Fatal error: Please read “Security” section of the manual to find out how to run mysqld as root!这是因为在测试的时候，使用root来启动的。而从安全角度来讲，不建议用root用户启动。在my.cnf中指定用户：12[mysqld]user=mysql SELinux导致启动失败12345Initializing MySQL database: mysqld: Can not create directory /data/mysql/ (Errcode: 17 - File exists)2016-09-20T01:51:47.062108Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated.Please use --explicit_defaults_for_timestamp server option (see documentation for more details).2016-09-20T01:51:47.064457Z 0 [ERROR] Aborting[FAILED] 确认datadir 目录属主 属组均为mysql 用户，应该不是用户权限的问题，这时想起SELinux 默认是开启状态，会不会是SELinux 的问题，为了确认问题，临时关闭SELINUX1#setenforce 0 一段时间之后，机器被重启，MYSQL启动的时候又起不了了，报如下错误：123456782017-05-18T07:25:02.333924Z 0 [ERROR] InnoDB: Operating system error number 13 in a file operation.2017-05-18T07:25:02.333944Z 0 [ERROR] InnoDB: The error means mysqld does not have the access rights to the directory.2017-05-18T07:25:02.333952Z 0 [ERROR] InnoDB: os_file_get_status() failed on ./ibdata1. Cant determine file permissions2017-05-18T07:25:02.333961Z 0 [ERROR] InnoDB: Plugin initialization aborted with error Generic error2017-05-18T07:25:02.974436Z 0 [ERROR] Plugin 'InnoDB' init function returned error.2017-05-18T07:25:02.974455Z 0 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.2017-05-18T07:25:02.974463Z 0 [ERROR] Failed to initialize plugins.2017-05-18T07:25:02.974469Z 0 [ERROR] Aborting 问题同样是因为SELinux没有关闭导致的。 字符集配置的问题启动失败，LOG中报错。原来在5.1版本时，为了解决中文乱码问题设置默认字符集为utf8时，在my.cnf内的 [mysql] 和 [mysqld] 项中都是写：default-character-set=utf8 ，到了5.5版本以后的版本， [mysql] 项内可以这么写， [mysqld] 项内不能再这么写了，而是必须写：character-set-server=utf8，否则报错。 root账号默认密码的问题在低于Mysql 5.7.6的版本上，Mysql是使用mysql_install_db命令初始化数据库的，该命令会在安装Mysql的用户根目录下创建一个.mysql_secret文件，该文件记录了初始化生成的随机密码，用户可使用改密码登录Mysql并重新修改密码。对于Mysql 5.7.6以后的5.7系列版本，Mysql使用mysqld –initialize或mysqld –initialize-insecure命令来初始化数据库，后者可以不生成随机密码。但是安装Mysql时默认使用的是前一个命令，这个命令也会生成一个随机密码。改密码保存在了Mysql的日志文件中。在Centos 7系统上使用rpm命令安装Mysql后，mysql的配置文件是/etc/my.cnf，打开该文件，可以看到mysql的datadir和log文件等的配置信息，如下：12datadir=/var/lib/mysqllog-error=/var/log/mysqld.log 打开/var/log/mysqld.log文件，搜索字符串A temporary password is generated for root@localhost:，可以找到这个随机密码，通常这一行日志在log文件的最初几行，比较容易看到。使用找到的随机密码登录mysql，首次登录后，mysql要比必须修改默认密码，否则不能执行任何其他数据库操作，这样体现了不断增强的Mysql安全性。用临时密码登录之后，使用下面的语句修改默认密码： SET PASSWORD = PASSWORD(‘new password’); 软件编译安装问题configure: error: no acceptable C compiler found in $PATH See c configure: error: no acceptable C compiler found in $PATH Seeconfig.log’ for more details.你的机器里没有安装任何C语言编译器，可以安装gcc。 可以在安装盘里找到gcc相关的包进行安装，不过会比较繁琐，因为关联的包会比较多。 如果可以上网，使用yum安装是比较好的选择： yum install gcc可是执行1234567[root@localhost ~]# yum -y install gccLoaded plugins: katello, product-id, security, subscription-managerUpdating certificate-based repositories.Unable to read consumer identitySetting up Install ProcessNo package gcc available.Nothing to do 如果是这种情况，可以换一个repo,比如163或者aliyun的，执行完成之后再执行：12yum -y install gccyum install -y gcc gcc-c++ Nginx相关Nginx: error while loading shared libraries: libpcre.so.1解决[xxxx conf]# /usr/local/nginx/sbin/nginx/usr/local/nginx/sbin/nginx: error while loading shared libraries: libpcre.so.1: cannot open shared object file: No such file or directory 确认已经安装PCRE:[xxxx lib]$ cd /lib[xxxx lib]$ ls pcrelibpcre.so.0 libpcre.so.0.0.1[xxxx nginx]$ find / -type f -name libpcre.so. 添加软链接:ln -s /lib/libpcre.so.0.0.1 /lib/libpcre.so.1前面在一般的linux上可以解决此问题. 在有的操作系统上面,安装pcre后,安装的位置为/usr/local/lib/pcre在redhat 64位机器上, nginx可能读取的pcre文件为/lib64/libpcre.so.1文件.所以在改用下面的软连接: ln -s /usr/local/lib/libpcre.so.1 /lib64/]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Mysql</tag>
        <tag>Nginx</tag>
        <tag>Node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MSYQL总结之数据类型篇]]></title>
    <url>%2F2017%2F04%2F16%2Fmysql-data-type%2F</url>
    <content type="text"><![CDATA[说明：本文为工作十年回顾总结系列之MYSQL之数据类型篇，主要内容为《High Performance MSYQL》第3版笔记，以及网上流传的最佳实践，作为个人知识库存档备份，相关配图来自anxpp的博客，其他文中引用不再一一说明。 MSYQL支持数据类型非常丰富，支持所有标准SQL数据类型，如果算上同义词有近40种之多。常用类型主要有3类：数值类型，字符串类型和时间日期类型。 1.1 数值类型数值类型有两种，即整数（whole number）和实数（real number），而实数又分为定点数和浮点数，下面逐进行一说明。 1.1.1-整数类型整数类型最简单的数据类型，很好理解，无需多言。整数存储所占空间和取值范围如下表所示： 选型建议： 整数类型支持UNSIGNED属性，表示不允许有负值，表示正数范围上限提高一倍。 创建数据表的时候，可以为整数类型指定宽度，如INT（11），但这没有实际意义，只用于交互工具界面显示字符个数，对于存储和计算来说，INT（1）和INT（20）是相同的； INTEGER等同INT。1.1.2-实数类型简单来说就是带小数的数字。MYSQL即支持精确类型也支持不精确类型，其中：1）定点数，DECIMAL（同NUMERIC）用于存储精确的小数；2）浮点数，FLOAT、DOUBLE和REAL类型支持使用标准的浮点运算进行近似计算；3）选型建议： 浮点和定点都可以指定精度，但是相对于定点数来说，浮点类型在存储同样范围的值时，通常比DECIMAL使用更少的空间，所以应尽量只在对小数进行精确计算时才使用DECIMAL，比如财务数据。 在数据量比较大时，可考虑用BIGINT代替DECIAML，即将需要存储的货币单位根据小数的位数以相应的倍数即可，这样可避免浮点数存储计算不精确和DECIMAL精确计算代价高的问题。 1.2字符串类型MYSQL支持多种字符串类型，其中VARCHAR和CHAR是两种最主要的字符串类型。 CHAR，固定长度，长度可为从0到255的任何值，保存时右边填充空格，检索时尾部的空格被删除掉，所以存储时字符串右边不能有空格，否则检索和比较会出问题； VARCHAR为可变长字符串，长度可以指定为0到65,535之间的值，需要一个字节来记录长度(如长度超255，则用两个字节)； BINARY和VARBINARY，和CHAR和VARCHAR类似，存储的是二进制字符串，不同之处是它们存储二进制串，没有字符集，排序和比较基于列值字节的数值； BLOB和TEXT类型，为了存储很大的数据而设计的数据类型，分别采用二进制和字符方式存储。MYSQL把BLOB和TEXT当成一个独立的对象处理，存储引擎在存储时通常会做特殊处理； 枚举（ENUM）类型，枚举列可以把一些不重复的字符串存储城一个预定义的集合，在存储枚举时非常紧凑，会根据列表值的数据压缩到一个或者两个字节中； 位数据类型，使用紧凑的位存储数据，这些类型不管底层存储格式和处理方式如何，从技术上来说都是字符串类型。 字符串类型存储占用空间，如下图所示： 选型建议： VARCHAR类型用于存储可变长字符串，比定长类型更节省空间,对性能提升很有帮助，不过因为行是变长的，所以UPDATE时需要做额外的工作。所以下面的情况最好使用VARCHAR：字符串列的最大长度比平均长度大很多，列的更新很少； CHAR是定长的，所以CHAR适合存储很短的字符串，或者所有的值都接近一个长度，比如MD5值，手机号码，IP地址； 因为内部会将每个值在列表中的位置保存为整数，并且按整数进行排序，所以尽量不要用数字作为ENUM枚举常量，这种双重性很容易导致混乱。 1.3 日期和时间类型MYSQL有很多类型来保存日期和时间，DATE，TIME，DATETIME，TIMESTAMP，YEAR，并且大部分时间类型都没有替代品，不存在什么最佳选择，根据实际需要选择即可。 DATETIME，同时包含日期和时间信息，以’YYYY-MM-DD HH:MM:SS’格式检索和显示，支持的范围为’1000-01-0100:00:00’到’9999-12-31 23:59:59’； DATE，只有日期值，使用’YYYY-MM-DD’格式检索和显示，支持的范围是’1000-01-01’到’9999-12-31’； TIMESTAMP，包含日期和时间，范围’1970-01-0100:00:01’UTC到’2038-01-1903:14:07’UTC； TIME，以’HH:MM:SS’格式检索和显示(或对于大的小时值采用’HHH:MM:SS’格式)，范围可以从’-838:59:59’到’838:59:59’； YEAR，一个单字节类型，以YYYY格式检索和显示YEAR值，范围是1901到2155。 选型建议 除特殊行为之后，通常应该使用TIMESTAMP，因为它比DATETIME空间效率更高； 用整数保存时间戳的格式通常不方便处理，不推荐这样做； 存储比秒更小粒度的日期和时间怎么办？可以用BIGINT存储微妙级别的时间戳，或者使用DOUBLE存储秒之后的小数部分。 几个通用的选型原则除了上面各个类型中的“选型建议”，还有几条通用的原则： 更小的通常更好，尽量使用可以正确存储数据的最小数据类型，例如如果只存0-200，则tinyint unsigned更好，因为它们占用更少的磁盘，内存和CPU处理时间。不过要预见性，确保存储值的范围不超过； 简单就好，简单数据类型操作需要更少的CPU时间，比如整型比字符串类型操作代价更低，存储时间用内置数据类型比字符串更好； 尽量避免Null，尽量指定NotNull，因为Null值使得索引，索引统计和值的比较都更加复杂； 只分配真正需要的空间，可归入第一条，因为更长的列会消耗更多的内存，尤其是使用内存临时表进行排序或操作时会提别糟糕，最好的策略是只分配真正的需要空间。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSQL理论基础]]></title>
    <url>%2F2017%2F04%2F15%2Fnosql-base%2F</url>
    <content type="text"><![CDATA[最近整理资料，看到几年前的硕士论文，题目是《基于NoSQL的BRS系统的设计与实现》，内容虽然不是多高深，但是当时也花了很多精力才完成的。不过现在很多内容都遗忘了，有点可惜，今天从其中摘录NoSQL理论基础相关的部分，重新复习一下！对了，论文主要是讲述如何利用NoSQL技术来构建UILSMP平台中的BRS模块，即一套彩票销售平台的用户路由模块。 NoSQL兴起的背景NoSQL不是一个新概念，“NoSQL”这个词最早见于到1998年，但是直到2009年，NoSQL被Eric Evans用于描述非关系型数据库的特性，才是我们目前对NoSQL的普通认识。NoSQL这一技术理念的风靡和互联网的发展息息相关。在互联网发展的早期，传统的关系数据库很好的完成了它应该承担的角色，它们使用简单，功能强大，性能也不错，而且稳定性高，积累了大量的成功案例，尤其是为互联网的发展做出了卓越的贡献的MySQL，曾经是最主流的选择。 最近10多年，随着互联网的快速发展，WEB2.0热潮一浪高过一浪。用户量的爆发使得热门网站的访问量的急剧上升，大部分使用MySQL架构的网站开始出现性能问题，这时大家开始使用大量的缓存技术来缓解数据库的压力，Memcached作为一个独立的分布式的缓存服务器很快流行起来，但是由于数据库的写入压力增加，Memcached只能缓解数据库的读取压力，读写集中在一个数据库上让数据库不堪重负。这时大部分网站开始使用主从复制技术来达到读写分离，以提高读写性能和读库的可扩展性，MySQL的Master-Slave模式又成为最为流行的数据库架构。然后随着Web2.0的继续高速发展，MySQL主库的写压力开始出现瓶颈，这时分表分库又成了一个热门技术。 大数据量高并发环境下的MySQL应用开发越来越复杂，也越来越具有技术挑战性。虽然有一些技术实力强大的公司开发了透明的中间件层来屏蔽开发者的复杂性，但是依然避免不了整个系统架构的复杂性，并且分库分表的子库到了一定阶段又面临扩展问题。总之，传统的关系型数据库在应对WEB2.0网站尤其是超大规模和高并发的社交类型的WEB2.0动态网站时存在如下几个难以克服的问题： 高并发读写 ：社交类型的 WEB2.0网站通常要根据用户操作来实时生成动态页面，数据库并发负载要求非常高，需要要达到每秒上万次读写请求。而关系数据库在上万次SQL查询应用场景中尚可，面对上万次SQL写请求就无能为力了。 海量数据的存储和访问：对大型的社交类网站而言，每天都会产生海量的用户动态信息。对于关系数据库来说，在一张有几亿条数据记录的表中进行SQL查询操作，效率是非常低下甚至是不可忍受的- 高可扩展性和高可用性：在以往经典的WEB架构中，数据库往往是很难进行横向扩展的，对于需要提供24小时不间断服务的网站来说，对数据库进行升级和扩展是非常困难的事情，需要停机进行数据迁移。 在面对上述问题的同时，关系数据库的很多特性对于WEB2.0网站来说并不需要，例如： 事务一致性需求：很多WEB系统并不要求严格的事务，对读一致性的需求很低，甚至某些场景对写一致性要求也不高，所以数据库事务管理反而成了数据库高负载下一个很大的负担； 写实时性和读实时性需求：对关系数据库而言，插入一条数据之后立刻查询是肯定可以读出来这条数据的，但是对于很多WEB应用来说并不要求这么高的实时性； 复杂SQL尤其是多表关联查询需求：大数据量的WEB系统，都会回避多个大表的关联查询以及数据分析类型的复杂SQL报表查询，在实际开发过程中大多都是单表查询或者单表的简单条件分页查询，SQL的功能被刻意的回避和弱化。 总之，关系数据库在越来越多的应用场景下不再是最优的解决方案，为了解决这类问题，非关系数据库即NoSQL数据库顺应时代的需求而诞生了。 NoSQL数据库理论基础CAP理论2000年，Eric Brewer基于他在UC Berkley的理论工作以及在主持Inktomi期间积累的经验提出了CAP理论，后来Seth Gilbert 和 Nancy lynch两人证明了该理论的正确性。Brewer认为在分布式环境下设计和部署系统时，有三个核心的系统需求，分别是: Consistency（一致性），Availability（ 可用性，指快速获取数据）， Tolerance of network Partition（分区容忍性），并且这三个系统需求，最多只能同时满足两个。 Consistency（一致性），指一个服务是一致的完整操作或完全不操作[3]。具体来讲就是系统中对一个数据的读和写虽然包含多个子步骤并且会持续一段时间才能执行完，但是在调用者看来，读操作和写操作都必须是单个的即时完成的操作，不存在重叠。 Availability(可用性)，意味着服务是可用的（可以完成如上的操作或不完成）。Gilbert 和Lynch在其CAP定理的证明中很好地指出了，可用性通常在你最需要的时刻背弃你。网站通常在业务最繁忙的时刻挂掉，因为网站压力最大，而一个他人无法访问的服务对任何人都没有价值。 Partition Tolerance(分区容忍性)，如果应用和数据库运行在一个机器上，忽略规模的问题并假定代码都没问题，那么可以服务器是作为一种原子处理单元（atomic processor），这个原子处理单元要么工作要么不工作,如果down机就不可用，但不会造成数据不一致问题。而一旦开始将数据和逻辑分布在不同的系统节点上，就有形成partition的风险。假定网线被切断，partition就形成了，节点之间不能进行通讯了。 CAP 理论说在一个系统中对某个数据不存在一个算法同时满足 Consistency, Availability, Partition-tolerance三个特性，这里边最重要却又最容易被人忽略的是“对某个数据不存在一个算法”的限定词，这就是说在一个系统中可以对某些数据做到CP, 对另一些数据做到AP，就算是对同一个数据调用者也可以指定不同的算法，其中某些算法可以做到 CP，而另外一些算法可以做到 AP。 要做到 CP系统可以把这个数据只放在一个节点上，其他节点收到请求后向这个节点读或写数据并返回结果,串行化是可以满足这种要求的，但是如果报文可以任意丢失的话，接受请求的节点就可能永远不返回结果,要做到CA，一个现实的例子就是使用单点的数据库,要做到AP系统只要每次对写都返回成功，对读返回固定的某个值就可以了。如果系统关心的是C，则需要处理写操作失败的情形，而如果系统关注的A，那么读操作可能不能准确的读到写操作写入的最新值。因此系统的关注点不同，采用的相应策略也是不同的，只有真正的理解了系统的实际需求才能更好的利用CAP理论。对大型分布式系统尤其是WEB系统，A与P优先级要高于C，在系统设计过程中一般都会朝着 AP 的方向进行设计，然后利用其它技术手段来保证对于C的需求。 最终一致性理论在介绍CPA理论的时候,我们明确了一个不容忍网络分割的系统可以实现数据的一致性和可用性，即可以做到CA，这通常是用事务来实现的，即客户端和存储系统必须在同一个环境中，他们在特定的情况下作为一个整体失败，只有这样客户端才看不到网络分割。但是一个重要的事实是，在大型的分布式系统中，网络分割是难免的，因此这时数据的一致性和可用性就无法同时满足，这意味着我们必须做出选择，即放松一致性的要求，在网络分割的情况下允许系统保持可用性，或者要求严格的一致性，并接受某些时候系统不可用的结果。目前，大部分基于云的应用程序都倾向于可用性和分区容错性，通常不保证一致性，至少是即时的一致性，只要系统所有节点能够做到最终一致性就可以。最终一致性在牺牲了即时一致性的同时，使得系统能够得到恒定且扩展性极高的数据访问，事务处理会保证按既定的顺序执行，但是并不保证会立即反映到所有节点上。在一致性方面，所获得的惟一保证是所有节点上的数据最终会被同步。 BASE理论BASE是指Basically Available（基本可用）、Soft-State（软状态/柔性事务）和Eventually Consistent（最终一致性），是对CAP中的AP的延伸。在分布式环境中CAP只能取两者，因为网络分区的存在对可用性有着重要影响并且不可避免，所以互联网中的分布式系统大多会在一致性方面做一些平衡。虽然不能达到强一致性，但可以根据实际应用的需求特点采用适当的手段来达到满足业务需求的一致性效果，即我们这里所说的最终一致性。在具体实现上，可以结合同步和异步多种策略、SQL+NOSQL多种存储方案来满足应用需求。在单机环境中ACID是数据的属性，而在分布式环境中BASE就是数据的属性。单机环境对数据有着比较高的要求，而在分布式环境中因为网络分区性以及各种复杂特性，对数据也只能做基本的要求了。从关系型数据库的ACID理论到NoSQL的CAP、最终一致性和BASE理论，从单机系统到大的分布式系统，从SQL到NOSQL，互联网应用的大规模发展促使我们不断创造可替代旧方案的新技术。对于NoSQL数据库与关系型数据库的差别，可以做如下简单总结： NoSQL数据库的数据模型通常与实际需求更贴近。通常使用关系型数据库时，需要关心的问题是“数据库能提供哪些功能”，而NoSQL模型关心得更多的是“可以解决哪些问题”。 使用NoSQL数据模型，需要对存储的内部结构和实现算法有一定的了解,需要自己处理数据结构解析和数据的冗余复制问题。 NoSQL数据模型在前面的章节里面,重点关注的是NoSQL这一技术理念兴起的一些理论基础中，而本节内容系统地对NoSQL数据模型进行一些探讨。NoSQL数据模型大体上可以划分为下面几类：Key-Value存储、类BigTable数据库、文档数据库，全文索引引擎以及图数据库,下面对几种类型进行简述： Key-Value模型，是最简单也是最方便使用的数据模型，它支持简单的key对value的键值存储和提取。 有序Key-Value模型，一个大问题是它通常是由HashTable实现，所以无法进行范围查询，所以有序Key-Value模型就出现了，有序Key-Value可以支持范围查询。 类BigTable模型，虽然有序Key-Value模型能够解决范围查询和问题，但是其Value依然是无结构的二进制码或纯字符串，通常我们只能在应用层去解析相应的结构。而类BigTable的数据模型，能够支持结构化的数据，包括列，列簇，时间戳和版本控制等元数据的存储。 文档型存储，相对类BigTable存储又有两个大的提升，一是其Value值支持复杂的结构定义，二是支持数据库索引的定义。 全文索引模型，与文档型存储的主要区别在于文档型存储的索引主要是按照字段名来组织的，而全文索引模型是按字段的具体值来组织的。 图数据库模型也可以看作是从Key-Value模型发展出来的一个分支，不同的是它的数据之间有着广泛的关联，并且这种模型支持图的算法。 NoSQL主流产品Google为解决大数据的存储与计算而提出的GFS + Bigtable + Map Reduce应该是最早的NoSQL产品了，后来Hadoop、 Hypertable、Memcached，Tokyo cabinet，Redis,Dynamo，MongoDB,Cassandra等等NoSQL产品纷纷被推出，使得NoSQL技术理念广泛应用于互联网行业的各个关键领域,本节将对主流的NoSQL产品进行简述。 RedisRedis（Remote Dictionary Server）是一个由Salvatore Sanfilippo开发的key-value存储系统，和Memcached有些类似，但是它支持存储的value类型更多，包括string(字符串)、list(链表)、set(集合)和zset(有序集合)。这些数据类型都支持push/pop、add/remove及取交集并集和差集等更丰富的操作，而且这些操作都是原子性的,并且在此基础上还支持各种不同方式的排序操作。 HBaseHBase–Hadoop 是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase技术可在廉价PC服务器上搭建大规模结构化存储集群系统。HBase是Google Bigtable的开源实现，在具体使用过程中，可以利用Hadoop HDFS作为其文件存储系统，利用Hadoop MapReduce来处理HBase中的海量数据；利用Zookeeper作为协同服务。 Apache LuceneLucene 是Apache软件基金会一个全文检索引擎工具包，由Doug Cutting开发并捐献给Apache，Lucene的设计初衷是为软件开发人员提供一个简单易用的工具包，以方便的在系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎，为各种中小型企业应用提供全文检索功能。 Neo4jNeo是一个面向网络的数据库产品,也就是说它是一个嵌入式的、基于磁盘的、具备完全的事务特性的Java持久化引擎。Neo将结构化数据存储在网络上而不是表中，网络是一个十分灵活的数据结构，可以适应更加敏捷和快速的开发模式。 MongoDBMongoDB一款介于关系数据库和非关系数据库之间的NoSQL产品，是非关系数据库当中最像关系数据库产品的，本文后续章节会详细介绍这一NoSQL产品。 NoSQL产品选择虽然NoSQL这一技术理念发展已经比较成熟，也有了一批很成熟产品可供选择，但是在系统中如果选用NoSQL产品，考虑到目前大多数NoSQL产品的健壮性,稳定性欠佳，在使用过程中的学习成本，维护成本都不容忽视，存在着一定的风险。对于是否采用NoSQL这一技术理念以及采用哪一款产品都需要系统架构师进行谨慎的思考，下面提供一些选择思路： 关注系统的应用场景，而对应用场景的考虑要回到数据本身，考虑数据是否方便查询、管理和维护。由于NoSQL的产品设计思路和实现方式和传统的关系型数据库不同，不同的NoSQL产品有其自身侧重的方向，比如HandlerSocket、TTserver和Redis侧重Key-Value的高效读写效率，MongoDB侧重文档型的数据存储结构，HBase则是需要存储海量数据的BigTable实现。所以只有更深刻了解系统的应用场景，在此基础上尽量选择合适的并且是自身比较熟悉的NoSQL产品。在这技术发展日新月异的时代，新的产品和技术不断涌现，我们需要不断的权衡取舍，以能解决我们工作中的实际问题为出发点来做出选型，而不是盲目跟风，为了尝试新技术而采用新技术的做法是不可取的。只有我们有能力驾驭了新技术，新技术才能真正的为我所有，从而为产品创造价值。如果某一应用场景的数据本身是存在关系的,比如是基于系统用户的数据,关系数据库可能仍然是最佳的选择,完全可以满足系统的商业需求，没有必要刻意使用NoSQL产品。 如果确定要使用NoSQL产品，可以考虑采用跟随策略，向大的互联网公司看齐，通过调查业内比较著名的互联网公司的成功案例，并且尽可能的借鉴他们的设计方案，可以很好的规避一部分风险。比如新浪微博大规模使用Redis就是一个很好的案例,而Yahooh,Baidu大规模使用Hadoop也是一个很不错的可借鉴对象。 考察产品是否有稳定的团队维护以及开源社区是否活跃。目前很多的NoSQL产品都沦为了个人产品，版本很少更新，不断爆发的出来的问题得不到及时的解决，所以一旦在架构中选择了这种产品，对系统的建设将是一个非常被动的局面。 NoSQL技术相关产品的出现很大程度上是为了伸缩性(可扩展性)出现的，是为了海量应用出现的(海量按目前的市场,至少得20亿+) ,而不是一种通用的key-value应用。所以实现NoSQL产品(模型)有很多,但是尽量选用对可扩展性和海量数据支持比较好的产品。 NoSQL产品的安全也是一个非常重要的因素。很多时候我们认为系统内网是可靠的，但是一旦内网被攻破而使得系统暴露于外网，则系统会面临很大的风险。事实上，因为系统选择的防火墙的稳定性和防攻击能力都可能欠佳,如果选用了在安全方面做得不好NoSQL产品,意味着系统数据的极大风险，所以在安全性在NoSQL的技术选型上是非常重要的一个方面。基于上述选择标准和各个NoSQL产品的功能特性对比,在UILSMP平台的架构中我们决定选用MongoDB这一NoSQL产品，之所以选择MongoDB是因为它本身具有的一些功能特性和UILSMP平台的BRS模块应用场景非常契合，在后面章节的系统设计中，会进行具体说明。 NoSQL产品的主流设计模式在众多采用NoSQL技术的互联网应用中，有三种比较主流的模式： 以NoSQL为辅，这种模式不改变原有的以MySQL或Oracle作为存储的架构，使用NoSQL作为辅助镜像存储，用NoSQL的优势辅助提升性能。 以NoSQL为主，就是系统中完全采用NoSQL作为数据源来存储数据，在这种以NoSQL为数据源的架构中，最核心的就是NoSQL数据库的复制功能的实现。而当前的几乎所有的NoSQL都没有提供比较易于使用的复制接口来完成这种架构，对NoSQL进行复制协议的二次开发，需要更高的技术水平，所以这种架构看起来很好，但是却不是非常容易实现的。 以NoSQL作为缓存，大部分互联网应用的特点都是数据访问有热点，只有一部分数据是被频繁访问的。所以我们可以利用NoSQL来做数据的缓存。其实NoSQL数据库内部也是通过内存缓存来提高性能的，通过一些比较好的算法，把热点数据进行内存cache，而非热点数据则存储到磁盘以节省内存占用。由于其数据库结构的简单，从磁盘获取一次数 据也比从数据库一次耗时的查询划算很多。用NoSQL数据库做缓存服务器不但具有不错的性能。而且还能够Cache比内存大的数据。 从UILSMP系统层面来开，我们采用了第（1）种以NoSQL为辅的模式，系统用户数据和交易数据仍然存储在Oracle这一关系型数据库中，只是在系统某一模块的设计上采用了NoSQL技术，可以算作是一个辅助手段。从BRS单独一个模块来块来看，我们采用了第（2）种以NoSQL为主的模式，将用户和业务中心的路由信息完全存放在MongoDB这一NoSQL数据库中，完全没有其他关系型数据库的参与。 为什么选择MongoDB？从前文对MongoDB的简述中可以知道，MongoDB是一个处于关系数据库和非关系数据库之间的数据库产品，是NoSQL数据库中最类似关系数据库的。具体来讲，MongoDB具有如下特点： 数据类型丰富：MongoDB是面向文档数据库，所谓的“文档”可以跟关系数据库中的原来“行”概念进行类比。一条记录就可以表示非常复杂的层次关系，因为面向文档的方式可以将文档或者数组进行内嵌。MongoDB没有模式的概念，文档的键不会事先定义也不会固定不变。由于没有模式需要更改，应用层可以处理新增或者丢失的键，这样开发者可以非常容易地变更数据模型。因为这种模式自由的理念，我们不需要知道存储在MongoDB数据库中文件的任何结构定义。根据实际需要我们可以把不同结构的文件存储在同一个数据库里。 功能丰富强大：MongoDB除了拥有其他数据库产品所拥有的功能特性之外，还拥有一些独特的功能特性。比如MongoDB支持通用辅助索引，能进行多种快速查询，也提供唯一的、复合的地理空间索引能力，MongoDB可以自己直接在服务端存取JavaScript的函数和值。当然有些关系型数据库的常见功能MongoDB并不具备，比如联接（join）和复杂的多行事务，这种考虑是为了提高扩展性，因为这两个功能很难在一个分布式系统上实现。 性能非常卓越：MongoDB尽可能地将服务器所处理的逻辑交给客户端，这样精简的设计使得MongoDB获得了非常好的性能。性能是MongoDB的主要设计目标，围绕这个目标MongoDB在设计上还有很多独特的考虑，比如MongoDB使用了MongoDB传输协议作为与服务器交互的主要方式，极大减少了系统开销。 分布式支持良好：自动分片以支持云级别的伸缩性，支持服务器之间的数据复制，支持主-从模式及服务器之间的相互复制，复制的主要目标是提供冗余及自动故障转移。 可扩展性良好：开发者可以专注编写应用，不用考虑如何扩展。因为扩展问题是MongoDB设计之初就考虑到的，MongoDB可以自动在多台服务器之间分割数据，还可以平衡集群的数据和负载并且自动重排文档。如果系统需要更大的容量，只需要在集群中添加新服务器节点，然后让MongoDB数据库来自动处理剩下的事情。 管理十分方便：MongoDB的数据模型对开发者来说非常友好，配置选项对于管理员来说也很轻松，并有驱动程序和数据库shell提供的自然语言式的API，会让使用者关注编程本身而不是为存储数据烦恼。MongoDB尽量让服务器自治来简化数据库的管理，除了启动数据库服务器之外，几乎没有什么必要的管理操作。如果主服务器挂掉了，MongoDB会自动切换到备份服务器上，并且将备份服务器提升为活跃服务器。在分布式的环境下，集群只需要知道有新增加的节点，就会自动集成和配置新节点。MongoDB的管理理念就是尽可能地让服务器自动配置，让用户能在需要的时候整体设置。 在键/值存储方式（提供了高性能和高度伸缩性）以及传统的RDBMS系统（丰富的功能）架起一座桥梁是MongoDB的主要设计目标，根据官方网站的描述，MongoDB适合用于以下场景： 网站数据：MongoDB非常适合实时的插入、更新与查询，并具备网站实时数据存储所需的复制及高度伸缩性。 缓存：由于其高性能，MongoDB非常适合作为数据获取的缓存层。 大尺寸低价值数据：使用传统的关系型数据库存储此类数据会比较昂贵，可以考虑使用MongoDB来存储此类数据。 高伸缩性场景：MongoDB非常适合由数十或数百台服务器组成的数据库，MongoDB的路线图中已经包含对MapReduce引擎的内置支持。 用于对象及JSON数据的存储：MongoDB的BSON数据格式非常适合文档化格式的存储及查询。 当然，MongoDB在某些场景的使用上也会有一些限制，例如下面的几个场景就不适合使用MongoDB： 高度事务性的系统：例如银行或会计系统。传统的关系型数据库目前还是更适用于需要大量原子性事务的应用程序。 传统的商业智能应用：针对特定问题的BI数据库会对产生高度优化的查询方式。对于此类应用，数据仓库可能是更合适的选择。 需要SQL的场景，即说存储的数据之间关系性比较强，这种场景更适合使用关系型数据库。 MongoDB数据结构设计在设计MongoDB数据库里面存储的数据之前，首先需要明确MongoDB的几个基本概念： 文档，文档是MongoDB中数据的基本单元，多个键极其关联的值有序地放置在一起便是文档，这非常类似于关系数据库中的行，但是比行要复杂的多。MongoDB文档有几个特点：文档中的键/值是有序的；文档中的值不仅可以是在双引号里面的字符串，还可以是其他几种数据类型，甚至是整个嵌入的问的文档；还要注意的是MongoDB不但区分类型，还区分大小写。 集合就是一组文档。档类似于关系数据库中的行，集合类似关系数据库中的表。集合是无模式的，一个集合里面的文档可以是各式各样的。 MongoDB中多个集合可以组成数据库。一个MongoDB实例可以有多个数据库，相互之间可以是完全独立的，每个数据库都有独立的权限控制，不同数据库放置在磁盘的不同文件中。 在本系统中，需要在MongoDB中存储数据是用户和业务中心的路由信息，则文档结构可以设计如下：{“username”:”zhangsan”,”icard”:”310105197800384325”,”route”:”biz1”}在MongoDB中存储的文档中必须有一个”_id”键，这个键可以是任何类型，默认为ObjectId对象。在一个集合里面，每个文档都有唯一的“_id”值，来确保集合里面每个文档都能被唯一标识。如果有两个集合的话,两个集合可以都有一个值为123的“_id”的键，但是每个集合里面只能有一个“_id”是123的文档。ObjectId是“_id”的默认类型，它设计成轻量型的，不同的机器都能用全局唯一的同种方法方便生成它，MongoDB之所以采用ObjectId作为主键而不是其他比较常规的做法，因为在多个服务器上同步自动增加主键既费力还费时。MongoDB从一开始就设计用来作为分布式数据库,处理多个节点是一个核心要求。 如果插入文档的时候没有”_id”键，系统会自动创建一个，可以由MongoDB服务器来做这件事情，但是通常会在客户端程序完成，原因如下：虽然ObjectId被设计成轻量型的，非常易于生成，但是毕竟还是会产生系统开销，而在客户端生成则提现了MongoDB的设计理念，能从服务器端转移到驱动程序来做的事情就尽量让客户端来做。这种理念的背后有着这样一个基本事实，即便是像MongoDB这样的可扩展数据库，扩展应用层也要比扩展数据库层容易的多，将事务交给客户端来处理，就减轻了数据库扩展的负担。另外,ObjectId使用12字节的存储空间，每个字节两位十六进制数字，是一个24位的字符串,是“_id”是为了保持文档的唯一性而存在的。在UILSMP-BRS的所要存储的数据中，彩民用户名和彩民省份证都是唯一存在的，所以在UILSMP-BRS的MongoDB存储的数据中,不必使用ObjectId作为“_id”默认值，而是直接使用用户名作为“_id”的值，另外键“icard”和“route”也可以用更为简短的“id”和“rt”,这样可以更加节省存储空间，则文档设计可以优化成为：{“_id”:”zhangsan”,”id”:”310105197800384325”,”rt”:”biz1”}。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java异常处理总结]]></title>
    <url>%2F2017%2F04%2F12%2Fjava-exception-notes%2F</url>
    <content type="text"><![CDATA[说明：本文为工作十年回顾总结系列之Java语言之异常处理篇，主要内容为《Thinking in Java 》第四版和《Effective Java》第二版的阅读笔记，网上流传的最佳实践，以及个人工作总结的杂糅汇总，作为个人知识库存档备份，文中引用不再一一说明。 Java异常处理机制的目的，在于通过使用少于目前数量的代码来简化大型项目代码，提高项目的可靠性安全性，属于那种投入少但效果立竿见影的语言特性。 几个基本概念1.传统（C时代）错误处理机制大都是约定俗成的，不是语言特性，比如通过很多的if语句来判断可预见错误，但如果每次方法调用都去做彻底的错误检查，程序会变得很臃肿繁杂。解决办法是用强制规定的形式来消除错误处理过程中随心所欲的因素，Java中异常处理机制就是如此；2.“异常”这个词很形象，就如工作中出现了你没有预期到的问题，自己又无权处理，就只能找上级领导去搞定。Java异常处理机制的好处是降低错误处理的复杂度，在异常处理程序中，把“正常执行流程”和“出了问题怎么办的流程”代码区分，对代码的编写、阅读和调试都大有好处；3.区分“异常情形”和“普通问题”，普通问题是当前环境下可以解决处理的错误，而“异常情形”则是没有足够信息来处理，只能抛给上一级环境。考虑除数为0的情形，究竟是普通问题还是异常情况？ Java异常基本语法1.异常创建 和普通Java对象一样，用new在堆上创建，垃圾自动回收，对象被创建之后引用会交给throw。异常对象及其类型通常与方法返回参数不同，但从效果上看就是从方法返回的，可以简单把异常处理理解成一种不同的返回机制，两者有什么本质区别可不必深究。2.捕获异常 ①监控区域（guarded region）是一段可能产生异常的代码块（try块），后面跟着异常处理代码（catch块），catch块可以有多个，异常处理机制根据参数与异常类型进行顺序匹配，使用基类Exception可以捕获所有异常，应该将其放在处理列表的末尾；②栈轨迹 可利用printStackTrace()打印调用序列用来分析问题；③重新抛出异常 可以把捕获到的异常重新抛出，也可以调用fillInStackTrace()方法更新抛出点信息；④异常链 Throwable子类在构造器中可以接受一个cause作为参数，通过把原始异常传递给新的异常，即使在当前位置创建并抛出了新的异常，也能通过这个异常链追踪到异常发生的最初位置。只有Error，Exception和RuntimeException提供了带cause的构造期，其他类型的则要用initCause()方法。⑤使用finally进行清理 把除了内存之外资源恢复到它们的初始状态时，这类操作通常包括：已打开的文件或网络等；3.自定义异常 Java自带的异常类型不可能包括所遇到的全部问题，可以自己定义异常类。自定义的异常类必须从已有的异常类进行继承。异常是个完全意义的类，可为其定义任意方法，因受检异常往往指明了可恢复的条件，所以提供一些辅助方法尤为重要，调用者借此可获得一些有助于恢复的信息；4.异常限制 ①当覆盖方法时，只能抛出基类方法的异常说明里列出的那些异常，也可以不抛出任何异常；②异常限制对构造器不起作用，可以抛出声明之外的异常，并且派生类构造器不能捕获基类构造器抛出的异常；③异常说明本身并不属于方法类型的一部分，不能基于异常说明来重载方法；④对于在构造阶段可能会抛出异常，并且要求清理的类，最安全的使用方式是使用嵌套的Try子句；⑤抛出异常的时候，异常处理系统会按照代码书写顺序找出最近的处理程序，匹配的时候并不要求抛出的异常同处理程序所声明的异常完全匹配，派生类的对象也可以匹配其基类的处理程序。 Error错误：JVM内部的严重问题，无法恢复。Exception异常：普通异常，通过合理的处理，程序还可以回到正常执行流程，包括受检异常和非受检异常。非受检异常也叫运行时异常（RuntimeException），这类异常是编程人员的逻辑问题，Java编译器不进行强制要求处理。可以这样理解两者区别：受检异常提出的是“法律下的自由”，必须遵守异常的约定才能自由编写代码，非受检异常则是“协约性质的自由”，你必须告诉我你要抛出什么异常，否则不会处理。所谓不处理就是异常会直达最上层，甚至被终端用户看到。 《EffectiveJava》对于异常使用的建议第57条： 异常只用于异常情况之下 异常永远不应该用于正常的控制流；第58条： 对可恢复的情况使用受检异常，对编程错误使用运行时异常 如果期望调用者能够适当恢复，对于这种情况就应该使用受检异常。通过抛出受检异常，强迫调用者在一个catch子句中处理该异常，或者将它传播出去。第59条： 避免不必要地使用受检的异常 受检异常是很好的特性，但过犹不及，调用者要么处理异常要么继续抛出，增加了调用者负担。第60条： 优先使用标准的异常 代码重用很重要，对异常也不例外。Java平台类库提供了一组基本的未受检异常，它们满足了绝大多数异常抛出需要，所以尽量少用自定义的异常。第61条： 抛出与抽象相对应的异常 高层实现应该捕获底层异常，同时抛出可以按高层抽象进行解释的异常，这种做法称为异常转译（exception translation），其中一种特殊的异常转译形式是异常链（exception chaining）。异常转译也不应该被滥用。第62条： 每个方法抛出的异常都要有文档 利用Javadoc描述方法所抛出异常重要，要始终单独声明受检异常，并且利用Javadoc的@throws标记，准确记录抛出每个异常的条件。同时，为非受检异常建立文档也非常明智的。第63条： 在细节消息中包含能捕获失败的信息 异常类型的toString()方法应该尽可能多地返回有关失败原因的信息，细节信息应该包含有“对该异常有贡献的”参数和域的值。例如，IndexOutOfBoundsException异常的细节应该包含下届上届以及没有落在届内的下标志。第64条： 努力使失败保持原子性 一般而言，失败的方法调用应该使对象保持在被调用之前的状态，具有这种属性的方法被成为具有失败原子性（failure atomic）。大体有四种方法可以实现这种效果，具体查阅原书。第65条： 不要忽略异常 本条建议适用于受检异常和未受检异常，是一条显而易见但是常被违反的建议，空的catch块会使异常达不到应有的目的，就算真的不处理，也要包含一条说明，解释忽略原因！ 阿里巴巴Java开发规范异常部分最近看到一份阿里巴巴的开发规范，总结的很详细，非常有参考价值，这里拿来和上文进行对照。1.【强制】Java 类库中定义的一类RuntimeException可以通过预先检查进行规避，而不应该通过catch 来处理，比如：IndexOutOfBoundsException，NullPointerException等等；2.【强制】异常不要用来做流程控制，条件控制，因为异常的处理效率比条件分支低；3.【强制】对大段代码进行try-catch是不负责任的表现。catch时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码，对于非稳定代码的catch尽可能进行区分异常类型，再做对应的异常处理；4.【强制】捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的内容；5.【强制】有try块放到了事务代码中，catch异常后，如果需要回滚事务，一定要注意手动回滚事务；6.【强制】finally块必须对资源对象、流对象进行关闭，有异常也要做try-catch。如果JDK7以上，可以使用try-with-resources方式；7.【强制】不能在finally块中使用return，finally块中的return返回后方法结束执行，不会再执行try块中的return语句；8.【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。 说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况；9.【推荐】方法的返回值可以为null，不强制返回空集合，或者空对象等，必须添加注释充分说明什么情况下会返回null值。调用方需要进行null判断防止NPE问题；10.【推荐】防止NPE是程序员的基本修养。NPE产生的场景：①返回类型为包装数据类型，有可能是null，返回int值时注意判空；②数据库的查询结果可能为null；③集合里的元素即使isNotEmpty，取出的数据元素也可能为null；④远程调用返回对象，一律要求进行NPE判断；⑤对于Session中获取的数据，建议NPE检查避免空指针；⑥级联调用obj.getA().getB().getC()易产生NPE；11.【推荐】在代码中使用“抛异常”还是“返回错误码”，对于公司外的http/api开放接口必须使用“错误码”，而应用内部推荐异常抛出；跨应用间RPC调用优先考虑使用Result方式，封装isSuccess、“错误码”、“错误简短信息”；12.【推荐】定义时区分unchecked / checked 异常，避免直接使用RuntimeException抛出，更不允许抛出Exception或者Throwable，应使用有业务含义的自定义异常。推荐业界已定义过的自定义异常，如DAOException / ServiceException等；13.【参考】避免出现重复的代码（Don’t Repeat Yourself），即DRY原则。 说明：随意复制和粘贴代码，必然会导致代码的重复，在以后需要修改时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是共用模块。 实践总结在TIJ中Bruce Eckel最后总结：尽管异常通常被认为是一种工具，使得你可以在执行过程中报告错误，并从错误中恢复，但是所谓的恢复聊胜于无，不过报告功能室异常的精髓所在，Java坚定地强调所有错误都以异常形式报告这一事实，正是它远远超过异常的精髓所在。对于这一点，在实际项目中可谓是深有体会，既然程序会出问题，主要是开发人员开发忽略了一些关键点，如果没有正确合理的使用异常，并且留下相应的日志，在解决问题的时候就不能发现错误根源，也就不能快速解决问题，生产环境尤为重要！ （THE END）]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java编程思想</tag>
        <tag>十年总结</tag>
        <tag>异常处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9527，给自己的一碗新年鸡汤]]></title>
    <url>%2F2017%2F01%2F15%2Fhappy-new-year-2007%2F</url>
    <content type="text"><![CDATA[最近新办了张上海移动的手机号，在设备上选号的时候，才翻了两页就看到一个尾号9527的号码，觉得很熟悉念着也挺顺口，就立马去柜台交钱开了卡。说实话，这个时候我只是觉得这个号码很熟悉，并且隐约记得这个号码是电视剧《士兵突击》中许木木在钢七连的编号。 回到公司跟同事提了一句，说办了一个9527的手机号，同事听了表情夸张的笑笑，提醒我号码有点那啥。我有些诧异，立马上网查了查，发现网上对这个号码的讨论还真是热闹，不但百度百科有专门的页面，知乎也有好几个相关的问题，百度甚至还有一个专门的贴吧。不过看完各种解读，我惊讶的发现自己完全搞错了，许木木在钢七连的编号是4956不是9527，两个号码八杆子打不着！ 可9527这个数字这么热，它到底有什么神奇之处呢？原来，9527是在星爷电影里面屡次出现，尤其是在《唐伯虎点秋香》中被发扬光大的一个梗。不过早在《唐伯虎点秋香》之前，发哥在《监狱风云》中的囚徒编号就是9527，所以很多人认为星爷在《唐伯虎点秋香》中用发哥的这个编号，是暗自自己在华府的囚徒生活。因为9527在粤语中的谐音有“小弟弟该硬的时候不硬”，也就是“没种”的意思，再加上星爷的电影和大众各种牵强附会解读，9527也就有了“没种的卑微下人”的专属含义。除去《唐伯虎点秋香》这部电影，星爷在《逃学威龙》中饰演交警的编号也是9527。另外，在《功夫》中也有一张扑克牌的截图，不过我个人觉得有些牵强，毕竟截图能够认出来的牌还有其他几张。 抛开星爷，9527还有一种解释是爱江山更爱美人，因为在中国古代把数字分为阳数和阴数，奇数为阳，偶数为阴。阳数中九为最高五居正中，因而以“九”和“五”象征帝王的权威，称之为“九五之尊”，而27谐音为爱妻，妻子永远是自己心中最美的，合起来就是爱江山更爱美人。另外，把9527倒过来看，还有LZSB的意思！ 对于9527的诸种解读，大部分都是无厘头甚至牵强附会，而且几种含义还有互相矛盾的地方。我觉得大家之所以这么喜欢这个号码，最主要的还是因为星爷，还是因为《唐伯虎点秋香》这部电影。在电影中星爷饰演的唐伯虎虽然才高八斗风流倜傥，为了追求秋香唐伯虎费尽周折进了华府，不过也成了一个只有编号与狗同级的低等下人，每天被人欺负蹂躏。可唐伯虎毕竟不是真的下等奴仆，而是为了追求幸福而甘愿卖身为奴的唐解元，在华府他从只有编号的9527变成了华安，由下等奴仆变成由书童，又变成老师，最后则做回了唐伯虎，并且迎娶了秋香抱得美人归。这么喜闻乐见又励志的故事，大家怎么能不喜欢呢？ 星爷的电影是搞笑，可更多时候是笑中带泪，能让人体味到一种特别的悲怆，我想这应该和他自己成长经历应该有关吧？从跑龙套的士兵丙，再到后来世人膜拜的星爷，其中艰辛可以想见，而9527这样一个梗，何尝不是星爷对亲身经历的解构和自嘲呢？ 再联想的远一点，被我弄混了的许三多最初也是一个9527，是一个被所有人被所有人都看不起甚至厌恶的小角色。从山沟沟走到军营，从新兵连到五班，甚至到了钢七连，他不过是从一个“监狱”走进另一个“监狱”，从一个“华府”走进另一个“华府”，但是他靠着自己简单又朴素的信仰：“有意义就是好好活，好好活就是做很多有意义的事”，一步一步将自己淬炼成万里挑一的兵王，一个被誉为陆军巅峰的老A。同样，饰演许三多的王宝强，最初的时候何尝不是一个9527呢？一个农村出来的农家孩子，从群演成长为影帝成了导演，虽然去年的离婚案闹的天下皆知，但是这并不能否认他在事业上的成功！ 话说每年年末年初的时候，我总是很焦虑，因为我又长大了一岁，奔三之后就是奔四，可一年下来境况依然如故，工作生活都没什么长进，仍然是一个无足轻重的9527，像一个囚徒一样在生活，这到底是为什么呢？现在看来原因很简单，《士兵突击》中老团长有句话，“想要和得到，中间还有两个字，那就是要做到，你只有做到，那才能得到嘛”。 虽然很早就看过《士兵突击》，虽然不止一遍的看过《唐伯虎点秋香》，可是就像我把两个号码张冠李戴一样，就算我被感动的稀里哗啦，但我仍然只是一个看热闹的，那些简单朴素却又无比珍贵的道理，从来没有真正走进我的内心！电影里面的唐伯虎，现实中的星爷，电视剧里面的许三多，现实中的王宝强，最初都是寂寂无名的小人物，都是靠着自己无坚不摧的信仰，冲破牢笼的勇气以及全身心投入的热情，一步步的走出困境的！可我既没有所谓的信仰，又总是患得患失随波逐流，根本就没有去做过，又何谈“做到”呢？结果也只能是“得不到”了！ 2017年已经过去好几天了，希望在新的一年中自己能够找到所谓的“信仰”，想清楚自己到底想要什么，想得到什么？然后踏踏实实的去做，并且百分之一百的做到！]]></content>
      <categories>
        <category>时光漫步</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>9527</tag>
        <tag>士兵突击</tag>
        <tag>周星驰</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目管理杂谈]]></title>
    <url>%2F2016%2F12%2F19%2Fpm-by-talk%2F</url>
    <content type="text"><![CDATA[说明：本文写于15年10月份左右，作为自己工作八年的简单总结，现在看来有一些观点不够成熟，甚至是错误的，但是还是保持原貌放在这里吧～ 成为一个好的项目经理，曾经是我的很长一段时间的职业目标，不过现实有些残酷，自己的目标好像并没有实现，能勉强称得上二流就已经不错了！不过工作多年之后，现在的想法也改变了许多，或者说是成熟客观了许多，也就不太在乎什么一流二流的了，能把项目做好就完事大吉了！虽然以前一直不入流，但是毕竟也做了这么多年，半瓶子醋也是醋，所以专门抽了一些时间，总结了工作以来作为一个项目经理（或者是一个小的技术团队管理者）的所思所想，期望能为以后的职业生涯提供更好的指导，也算不枉这些年虚度的许多光阴。 一、项目管理方面的职业回顾自己八年多的工作生涯中，大体可以分为三个阶段，如下： 1.第一个阶段菜鸟期：07年参加工作到09年初，也就是参加工作的前两三年，大部分时间都是作为一个程序猿在写代码，做了一个创业型的项目以及两三个运营商的电信项目，算是从菜鸟到会干点活的过程。因为是在一个创业团队里面工作，所以分工不是很明确，要做的事情很多，而自己还算得上是一个踏实勤奋的人，所以很快得到了老板的信任，到创业项目结束的时候，我成了唯一留下来的人。那段时间经常出差，最多的是兰州和西安两个城市，除了工作之外印象最多能饱饱口福，兰州拉面和正宗的牛羊肉，西安肉夹馍和羊肉泡馍都是让人念念不忘的好东西。虽然那个时候就透露这浓浓的屌丝味，但好歹还是青葱少年！哎，往事不可追呀！在这个阶段，技术方面有了很大的提升，但是最大的收获还是关于项目实施的经验积累，以及对软件项目完整流程的深刻理解。 在实施现场碰到的各种突发问题让我学会了怎么灵活面对困难，怎么利用各种资源来解决问题，又怎么从混乱复杂的现场和时间要求非常紧张的情况下，推动项目上线。并且逐渐认识到，对于一个项目来讲研发只是其中的一个环节，而实现真正的商用，还有许多的环节和工作要做，但是研发过程的产出对项目最终上线又起着至关重要的作用！ 这种经历对身为研发人员来说的我，虽然辛苦，但是却很是珍贵。 2.第二阶段快速成长期因为一直留在最初的创业团队里面，所以当团队有了新的方向时，我便有机会带一个三五个人的团队，逐步介入了团队管理的工作。在做过一段时间之后，发现比起写代码来自己好像更适合这种工作，所以投入了很大的热情，也产生了重管理轻技术的错误想法，这是我现在非常后悔的一件事情。因为对项目管理盲目热情，花了很大力气考上海交大软件学院的MSE（软件工程硕士），学习项目管理专业，期间又把PMP证书考下来，算是一偿夙愿。正巧在这段时间，随着公司的发展和团队规模的不断扩大，自己做了不少事情，进步也很大。 3.第三阶段瓶颈期因为公司规模扩大，在无锡创立了分公司，带着对未来的美好期望转战无锡，本想着大干一场，可是最终事与愿违！最近两年，彩票行业的发展受政府政策干预太多，而公司领导层的策略又存在某种失误，导致三四年的时间里面并没有做出什么成绩。作为我个人来讲，在这期间感觉也收获甚少，一个原因自然是因为公司发展不顺利，没有更好更大空间去历练，另外一个则是工作的定位其实不是真正意义上的项目经理，更多的是一个研发经理，负责的也是具体的研发管理工作，主要是对内，对外接触的机会不是很多，所以在项目管理方面的提高也不多。另外，再加上错误的世界观，也导致在技术两个方面也没有大进步，本来想着两手抓两手都要硬，事实却是两手空空，想来颇为遗憾。 二、对所谓“管理”的理解虽然公司发展受阻，自己发展也很难让人满意，但毕竟折腾了这么几年，不管是在项目管理还是团队管理上，多少还是有些收获的。下面挑几个比较重要的，感触比较深的主题，来谈一下自己对管理的一些理解，内容包括了项目管理和团队管理，因为我觉得这两者有时候不太容易区分，所以在不特别说明的情况下，两者都包括在内。 1.个人管理能力如何习得？虽然拿了项目管理专业的学位，考了PMP的证书，但是我现在觉得个人的所谓管理能力，大体还是与生俱来的的，各种学习和培训只能是锦上添花之举。因为不管是项目管理还是团队管理，最本质的还是人的管理，而人性复杂，与人沟通的能力多是自然天成，而非后天习得！另外，说一下在上海交大读书的情况，因为上海交大的项目管理专业有些特别，所有的项目管理专业是一个人授课，是软件学院的特聘教授张艳红。说实话，她的课还是很与众不同的，每一届都会有受不了她的学生转专业，在学生中争议很大。我个人的感受是她上课的形式确实不错，比一些照本宣科的老师好很多。不过虽然形式很好，但是项目管理的真正内容却并没有装到这个形式里面，有点花拳绣腿的感觉，而且感觉她的课大都在挖掘人性的黑暗面，给我的感觉始终很压抑。在她的项目管理课上，我最大的也是唯一的收获，就是作为项目经理，为了顺利完成项目所必须具有的那种一种勇往直前的精神。至于其他的细节方面的管理技巧，包括各种模型之类，我确实不太感冒！当然，上她的课你还能结实几个关系不错的同学，因为你们必须在一起受虐，这个过程会让你和同组（一个虚拟公司）的同学亲近很多。 2.技术和管理可否兼具？俗话说，鱼和熊掌不可兼得，那么对一个人来说，技术和管理能否兼顾呢？肯定有人可以做到，而且在技术公司里面，既精通技术又有管理能力的人是必须的。不过毫无疑问的是，这种人还是比较少的，虽然我个人一直口口声声的说要成为一个技术型的管理者，但是做的其实并不好，尤其是在技术方面进步和积累不够。我不得不承认，在时间和精力有限的情况下，这两个方面很容易顾此失彼。还想说一下公司层面（管理层）对这件事事情的看法，我个人感觉相当一部分公司对管理岗位并不重视，尤其是技术型的公司，是维技术论的。其实，我个人也认为大牛级别的人是不需要所谓管理的，不需要设置很多条条框框的。但事实上对大部分公司而言，项目团队里面并不是所有人的都是大牛，很多技术人员水平和个人素养参差不齐，所以一个好的项目经理还是很重要的，否则很容易出现混乱不堪的局面。尤其是一个自视甚高但是又没有起码的管理能力的来说，对团队下面的人来说，可能会是噩梦！ [2017年1月11日增加]最近在ruanyf的博客里面看到一篇文章，是介绍大科学家理查德.汉明的一篇演讲（演讲为《你和你的研究》），他的演讲中有下面一部分内容： 如果你想成为一名伟大的研究者，就不要成为一个公司的总裁。你得清楚你要什么。一天，我到我的老板Bode那里，对他说：”为什么你要当这个部门的头呢？为什么你不去当一名大科学家呢？” 他说：”Hamming， 我有远见，知道贝尔实验室的数学部分要怎样，如果要让这个”远见”得到共识，我就得当上部门的头。”当你觉得你想干什么的远见，正好在你的能力范围内，你就应努力获取它。如果有一天你的远见大大超过了你的能力时，你就应该去做管理工作。而且，远见越大，你就应做越大的管理。如果你拥有一个关于整个实验室应该向何处去，或者有关整个贝尔系统，你就得到该去的位子让它实现。你从底层是无法轻易让它实现的。这取决于你的目标和对目标的渴望。我选择回避管理工作因为我更希望做我容易应付的事。但这是我的选择，只对我起作用。每个人有权做出自己的选择，保持一个开放的心态。但别试着两样都占。现在我觉得上面这段话是对技术和管理如何选择的终极答案，我之前的想法有点太小儿科了，其实一个小的TeamLeader，项目经理的的所谓管理并非真正的管理，真正的管理应该是需要远见，可以推动一个机构（组织甚至行业）变得越来越好，作出开创性的工作！ 3.关于流程的那些事儿刚刚成立的初创公司自然谈不上什么流程，但是当团队和项目逐渐扩大之后，确立一套简洁有效的研发管理流程肯定是必须的。不过以我的经验，很多时候制定流程是一回事，真正让流程有效的执行运转起来则是另一回事，或者完全是另外一回事。因为受过比较专业的系统学习，曾经负责牵头制定了公司的研发流程，概述如上图所示，基本上是传统的比较主流的研发流程+关键的环节的敏捷执行，简而言之就是在RUP的外壳下，装了一个敏捷的心！不过后来因为各种原因，制定好的流程执行的并不尽如人意！现在想来，对一个公司来讲，流程肯定是重要且必须的，不过跟男女之间谈恋爱一样，只有合适的才是最好的！而且一个稳定高效的流程体系，应该是渐进而成的，绝不是突然心血来潮的推行一个高大上的流程体系，然后整个项目甚至公司的效率就会提升。当团队的大部分人工作都很高效的时候，不要随便折腾，当虽然项目和公司发展，出现不和谐的声音，效率下降的时候，就要仔细分析原因，有针对的性的优化原有流程体系。当然，这是一个不断迭代的过程。 4.PMP有什么价值？在交大读书的时候，在张艳红老师的带动下，花了一些精力把PMP的证书考了下来，我个人认为还是是很有价值的，当然有价值的不是证书，而是PMBOOK里面讲的项目管理的知识体系以及知识体系之上的项目管理思想。这块内容比较多，暂时先不多谈，等有时间再详细说说！ 5.关于敏捷的执行公司曾经几度试图推行敏捷开发的模式，但是效果都不尽如人意。以我个人的经验来看，敏捷是个很迷人也很迷惑人的东西，是把双刃剑，用的好了固然可以提升效率更好的完成产品研发，但是用不好就是变成怨声载道，流于形式！那么怎么样才能用好呢？我觉得培训和推广应该是第一位的，说不好听的就是洗脑，需要让全部的团队成员接受并认同这样一种工作方式，而不是上来就逼着大家去执行，当一个人不理解一件事情的时候，非但做不好，甚至有可能成为很大的阻力。如果能让团队所以人都认同了，剩下的执行应该就不会有太大困难了，只是形式和细节上的一些裁剪了。对于敏捷，我还有一种歪理邪说，那就是敏捷其实是反人性的！可以先考虑一个问题，那就是既然大家都说敏捷好，可是为什么会有人不接受，甚至很排斥呢？我个人认为是人性太复杂，并不是所有的人都想努力工作努力提升，有些人是非常被动的人，他们喜欢混日子，当一天和尚敲一天钟，但是敏捷这种工作方式是特别强调人的自我驱动自我管理的，所以这里的存在的冲突是相当大的，所以让所有人都接受这样一种方式，并不是一件容易的事情。 6.对CMMI认证的个人观点曾经参加过两次CMMI三级的认证评审，所以多少可以说上那么几句。我觉得CMMI认证这事完全是劳民伤财的一件事情，因为认证的过程就是作假造假的过程，而且认证结束后，也并不能给你的企业和研发过程带来明显的改进。当然，可能有些企业会做的不错，但我觉得是凤毛麟角！（希望我是一叶障目，没见过世面的井底之蛙！）这件事情甚至让我想起学生时代，每次有领导来学校检查，就各种打扫卫生整理内务，老师补教案，甚至组织一批学生帮忙补教案，此等歪风邪气何时能够销声匿迹呢？不过，这里我需要特别强调一下，我反对的是CMMI认证这回事，不是反对CMMI这套体系，这套体系能留持续流传这么久这么广，甚至成为一桩生意，肯定是有价值的！ 7.面对“刺头”该怎么办？在过往的经历中，虽然得到了大部分同事的认可，但是也不止一次的碰到让你难堪的刺头，这种情况下该怎么处理呢？这个问题曾经困扰过我一段时间，好长时间没有答案！下面是我现在的一些想法： 首先要防患于未然，在组建团队和招人的时候，要有一双雪亮的眼睛，尽量不要让这种人成为你的团队成员。不过这只是最理想的情况，因为并不是所有的团队成员都由你自己来招，而且你也未必有这样一双火眼金睛； 我这里所谓的“刺头”也只是一个笼统的概括，是指对团队正常运转和前进起伤害左右的一些团队成员。比如有些人工作挑三拣四，而且效率低不说还总是寻找各种借口给自己开脱，最后甚至形成你激烈的对立面。还有一些可能不激烈，但是看上去也很努力，分配或者认领任务的时候说的很好，但是检查工作成果的时候却又总是找个借口拖延，诸如此类； 如果是中途接手的项目，你不得不面对一两个这样的人，首先要做的还是尽量争取让他们认同你。这里能做的事情可以是推心置腹的沟通，工作内容上给比较合适的安排等等； 在你做过努力之后，你发现事情没有得到改观，那么这时候要做的，只能是将他清除出队伍了，或者跟上级领导沟通将其调离，或者是弃之不顾让其放任自流。因为你要的事情很多，你没有时间和精力浪费在这种人身上，项目经理不是圣母！ 三、关于未来往者不可追，来者尤可鉴。虽然未来会怎么样，自己不好预测，但是有句话叫做不忘初心，所以未来的职业道路上，我还是会坚持技术和管理兼具的目标，继续努力，努力拼搏，万死不辞，诸如此类，而且以后还会在产品研发上拓展一下，因为搞出一款改变世界的产品确实是一件很酷的事情，虽然很难，我心往之。。。，O(∩_∩)O~。]]></content>
      <categories>
        <category>项目管理</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
        <tag>PM</tag>
        <tag>PMP</tag>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memcached升级总结]]></title>
    <url>%2F2016%2F11%2F14%2Fmemcached-update%2F</url>
    <content type="text"><![CDATA[缘起公司的几个小项目部署在阿里云上，最近收到封安全相关的邮件，内容如下： 尊敬的用户： 2016年10月31日,Memcached官方发布安全补丁修复多个远程代码执行漏洞，黑客可以利用这些漏洞窃取在Memcached中存放的业务数据，或导致Memcached服务崩溃从而造成拒绝服务等危害，风险等级较高，为了确保您在云上业务安全性，请您关注，具体详见安全通告信息，漏洞详情。同时建议您前往安骑士控制台使用“基线检测功能”检查是否受该漏洞的影响， 感谢您对阿里云的支持！ 项目确实在用Memcached做数据缓存，所以赶紧上网查看升级方案，但是“走遍千山万水”，也么有找到如何打补丁，将现有版本升级到最新版本，真是奇哉怪哉！最后在自己的虚拟机上做了下实验，升级方式是删掉旧版本后重新安装新版本，或者直接将新版本安装在另一个位置，然后启动新版本即可！ 具体升级过程：1.查看当前版本memcached进程，杀死进程；2.查看已安装版本，卸载之（不管也可以）；3.上传最新版本XXXX.tar.gz，解压：tar -zxvf memcached-1.4.33.tar.gz编译：./configure –prefix=/usr/local/memcached-1.4.33在执行编译的过程中，提示依赖libevent没有安装。这个地方比较奇怪，因为之前已经安装过其他版本的memcached，所以libevent确认是装过的。网上搜了一下，发现可能是因为libevent-devel没有装导致的，但是使用yum命令去装的时候，提示 no package available，解决方案见下文。4.安装：make &amp;&amp; make install5.启动：/usr/local/memcached-1.4.33/bin/memcached -d -m 128 -u root -p 11211 -c 1024 -P /tmp/memcached.pid6.测试：telnet 127.0.0.1 11211，然后输入stats查看状态；7.重启应用：重新启动相关应用。 附录1：解决yum命令no package available的方案说明系统没有注册，YUM不可用。改变yum源尝试。任选其一参考：http://mirrors.aliyun.com/help/centoshttp://mirrors.163.com/.help/centos.html 参照http://mirrors.aliyun.com/help/centos里面的教程，执行如下几行代码，然后再执行yum -y libevent-devel命令即可！ 123mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repoyum makecache 附录2：解决telnet: command not found…问题就是安装telnet命令的，过程如下：12345678910111213141516171819202122232425[root@localhost local]# rpm -qa telnet-server[root@localhost local]# rpm -qa xinetd[root@localhost local]# yum list | grep telnettelnet.x86_64 1:0.17-59.el7 base telnet-server.x86_64 1:0.17-59.el7 base [root@localhost local]# yum install telnet-server.x86_64Loaded plugins: fastestmirror, langpacks......//省略Complete![root@localhost local]# yum install telnet.x86_64Loaded plugins: fastestmirror, langpacks......//省略Complete![root@localhost local]#[root@localhost local]# yum list | grep xinetdxinetd.x86_64 2:2.3.15-12.el7 base [root@localhost local]# yum install xinetd.x86_64Loaded plugins: fastestmirror, langpacks......//省略Complete![root@localhost local]# systemctl enable xinetd.service[root@localhost local]# systemctl enable telnet.socketCreated symlink from /etc/systemd/system/sockets.target.wants/telnet.socket to /usr/lib/systemd/system/telnet.socket.[root@localhost local]# systemctl start telnet.socket[root@localhost local]# systemctl start xinetd]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>memcached</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一元夺宝算法设计]]></title>
    <url>%2F2016%2F09%2F27%2Fwy-yydb-alg%2F</url>
    <content type="text"><![CDATA[缘起网易“一元夺宝”这个产品已经运营很多年了，现在类似的产品也有好多。虽然此类产品大都宣称自己是以众筹的模式进行商品销售，但本质就是博彩的一种，以小博大，只不过奖金换成实物罢了。此类产品业务逻辑很简单，也很容易理解：将某一商品总销售价格分成N份，每个参与的用户购买一部分份额以赢取商品。前段时间公司也帮客户开发了一套类似的小系统，出现了一些设计上的偏差，本文总结一二,备查！ 核心业务流程简要说明： 首先商品（GOOD）可以有很多种，每种商品有很多期（ISSUE），某一期销售完成后可以自动添加新一期；每件商品总价被分成很多份，每份价格1元，10元，或者百元，每份对应一个号码； 用户下单（ORDER）按份数购买某一商品某一期，可以一次购买多份，甚至把某一商品某期全部包号； 销售期完成之后，系统自动对该期进行开奖，开奖算法如下（参考网易一元夺宝）： 开奖之后，把奖品寄送给中奖用户； 系统设计方面，整体来讲没有什么难点，因为商品，商品期的发布，状态流转，开奖等流程都比较明确，不过系统开发过程中还是忽略了一下业务细节的特殊姓，比如对幸运号码的处理。其他诸如开期，开奖的流程，也出了一些问题，但都不是设计上的问题，可以按部就班的解决。下面对幸运号码相关设计详细说明一二。 幸运号码分配算法根据业务要求，每种商品每一期的号码池是：10000001（原始数） + P（商品价格），每份对应其中一个号码， 而最终的中奖号码也在这组数据里面产生。问题是用户下单的时候，该怎么把幸运号码随机分配给用户？ 方案A： 初始方案，是有一个ORDER表，用来记录用户订单，还有一个LUCK_NUM表，用来记录每一条幸运号码，LUCK_NUM表关联到ORDER表和ISSUE表中；用户每次下单购买n（0&lt;n&lt;=N）份，从10000001-P中取n个随机数出来作为幸运号码，但是因为每个幸运号码只能用一次，所以取随机数的时候要把已经用掉的号码去掉，这个地方就要考虑代码的性能问题；后来觉得不太方便，就改成每次创建新ISSUE时，把对应的所有的LUCK_NUM表的记录先创建出来，然后下单的时候从LUCK_NUM表中分配未用的幸运号码，已用的幸运号码设置一个标记位。【注意：这里幸运号码不是中奖号码！】目前系统已经按照方案A上线，但是现在考虑下来，此方案有很多缺点，导致了一些问题。比如因为有LUCK_NUM这个表，导致系统自动创建新的ISSUE时，速度可能不够快，还有当用户购买大单时，要更新LUCK_NUM表的耗时过长，用户体验很差！而且随着系统运营时间的增加，LUCK_NUM表的记录会爆炸性增长，进而影响系统性能。 方案B： 根据上面的问题，考虑了一个优化方案，去掉LUCK_NUM表，增加一个LUCK_NUM_POOL表，就是不要对每一期夺宝商品都搞一批幸运号码出来，而是对某一种商品只产生一批幸运号码，然后重复使用，因为同一种商品价格一样，所有幸运号码都是一样的，所以LUCK_NUM的存在有些鸡肋。另外，为了避免每次下单都更新LUCK_NUM_POOL的记录，有一列是无序随机的幸运号码luck_num，还有一列是顺序编号sort_num，还需要在ISSUE表中新增一个游标字段，记录每次用户下单之后尚未使用的sort_num的起始值，这样应该还可以解决一些用户大量访问下达的并发问题。 因为目前公司规模不大，最近接的一些外包的小项目，需求不完善，业务流程也不甚明确，所以导致设计的往往采取尽可能简化的策略，但是只要称得上一个项目，又往往是麻雀虽小五脏俱全，总是会遗漏一些点，所以做起来还是挺痛苦的！]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>一元夺宝</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《大数据时代》阅读笔记]]></title>
    <url>%2F2016%2F03%2F15%2Fbig-data-notes%2F</url>
    <content type="text"><![CDATA[说明：这本关于大数据的畅销书已经出来两三年了，现在才断断续续的读完，有些不应该！不过为了深入了解大数据相关的知识，本着精读的原则做了一些笔记，不过读完之后会发现，其实谈的内容还都是很容易理解的，毕竟这书本身也只是泛泛而谈，没有特别难懂的细节。不过因为书中有很多案例，可以让读者很直观的了解大数据到底是什么？到底能给世界带来什么样的变化？所以还是很值得一读的！ 引言：一场生活，工作与思维的大变革大数据，变革公共卫生大数据，变革商业大数据，变革思维大数据，开启重大的时代转型预测，大数据的核心就是预测，它通常被视为人工智能的一部分，或者更确切的说，被视为一种机器学习。不过大数据不是要教机器像人一样思考，相反它是把数学算法运用到海量数据上来预测事情发生的可能性。数据时代处理数据理念上的三大转变：要全体不要抽样，要效率不要绝对精确，要相关不要因果。 第一部分 大数据时代的思维变革01.更多：不是随机样本，而是全体数据小数据时代的随记采样，最少的数据获得最多的信息，比如人口普查。原理是当样本数量达到某个值之后，我们从新个体身上得到的信息会越来越少，就如同经济学中的边际效益递减一样。缺陷：随机采样的功能依赖于采样的绝对随机性，但是实现采样的随机性非常困难，一旦采样过程存在任何偏见，分析结果就会想去甚远。随机采样不适合考察子类别的情况，当人们想了解更深沉次的细分领域时，随机采样的方法不可取。随机采样也需要严密的安排和执行，人们只能从采样数据中得出事先设计好的问题的结果。全数据模式，样本等于总体。 02.更杂：不是精确性，而是混杂性只有5%的数据时结构化且能适用于传统数据库的，如果不接受混乱，剩下的95%的非结构化数据都无法被利用，只有接受不精确性，我们才可能打开一扇从未涉足的世界的窗户。大数据通常用概率说话，而不是板着“确凿无疑”的面孔。大数据不仅让我们不再期待精确性，也让我们无法实现精确性，接受数据的不精确和不完美，我们反而能更好的进行预测，也能够更好地理解这个世界。混杂性，不是竭力避免而是标准途径。比如标签，清楚的分类呗更混乱却更灵活的机制代替了，因为这些机制才能适应改变着的世界。传统的关系数据库是为数据稀缺的时代设计的，所以能够也需要仔细策划。但是现在这种数据存储和分析的方法越来越和现实相冲突，这导致了新的数据库设计的诞生，它们打破了关于纪录和预设场域的成规。最能代表这个转变的就是Hadoop的流行。 03.更好：不是因果关系，而是相关关系关联物，预测的关键。相关关系的核心是量化两个数据之间的数理关系，相关关系强是指一个数据值增加时，另一个数据值很有可能也会随之增加。建立在相关关系分析法基础上的预测是大数据的核心。是什么？而不是为什么？与常识相反，经常凭直觉而来的因果关系并没有帮助我们加深对这个世界的理解。 第二部分 大数据时代的商业变革04数据化：一切皆可以量化1.莫里的导航图，大数据的最早实践之一2.数据，从最不可能的地方提取出来。庞大的数据库有着小数据库没有的价值，大数据的核心就是挖掘出庞大数据库的独有的价值。3.数据化，而不是数字化，两者大相径。信息技术变革随处可见，但是如今信息技术变革的重点在T上，而不是I上，现在是时候开始关注I本身了。4.量化一切，数据化的核心。1）当文字变成数据，谷歌数字图书馆 &amp; 亚马逊。亚马逊深谙数字化内容的意义，二谷歌触及了数据化内容的价值。2）当方位变成数据，GPS，地理位置信息收集3）当沟通变成数据，社交关系，Facebook，Twitter等； 05.价值：取之不尽，用之不竭的数据创新数据的真实价值就像漂浮在海洋中的冰山，第一眼只能看到冰山的一角，而绝大部分都隐藏在表面之下。ReCaptcha与数据再利用，2000年，路易斯.冯.安（Luis Von Ahn）验证码（全自动区分计算机和人类的图灵测试）；ReCaptcha ?? 强调了数据再利用的重要性。判断数据的价值需要考虑到未来它可能被使用的各种方式，而非仅仅考虑其目前的用途。数据的潜在价值有三种最为常见的释放方式：基本再利用，数据集集合和寻找“一份钱两分货”，而数据的折旧值，数据废气和开放数据则是更为独特的方式。数据创新1:数据再利用：典型的例子是搜索关键词，以往的查询也可以变得非常有价值。数据再利用的价值对于那些手机或控制着大型数据集但目前却很少使用的机构来说是个好消息，信息喷泉，数据坟墓。互联网和科技公司在利用海量数据方面走在了最前沿，因为他们紧紧通过在线就能收集大量的信息，分析能力也领先于其他行业。数据创新2:有时，处于休眠状态的数据的价值只能通过与另一个截然不同的数据结合才能释放出来。随着大数据的出现，数据的总和比部分更有价值。数据创新3:可扩展数据，零售商店摄像头，谷歌街景与GPS收集，数据创新4:数据的折旧值，随着时间的推移，大多数数据都会失去一部分基本用途，在这种情况下，继续依赖旧的数据不仅不能增加价值，实际上还会破坏新数据的价值。数据创新5:数据废气，微软与谷歌的拼写检查。用来描述人们在网上留下的数字轨迹的艺术词汇。数据废气是许多电脑化服务背后的机制，如语音识别，垃圾邮件过滤，翻译等。数据废气可以成为公司巨大的竞争优势，也可能成为对手强大的进入壁垒。数据创新6:开放数据。大数据对于公共部门的适用性同对商业实体是一样的：大部分的数据价值都是潜在的，需要通过创新性的分析来释放。数据估值：计算价值不再是将其基本用途简单地加总，但是如果数据的大部分价值都是潜在的，需要从未知的二次利用提取，那么人们目前尚不清楚应该如何估算它。 06.角色定位：数据，技术与思维的三足鼎立1.我们正处在大数据的早期，思维和技术是具有价值的，但是最大部分的价值还是必须从数据本身中挖掘。2.所谓大数据思维，是指一种意识，认为公开的数据一旦处理得当就能为千百万人急需解决的问题提供答案。3.大数据价值链的3大构成：1)数据本身，Twitter通过独立公司授权给别人使用；2)技能;3)思维，Jetpac通过用户分享的旅行照片来为人们推荐下次旅行的目的地。4.公司应该把自己放在信息链的核心，这样它们竟能扩大规模，挖掘数据的价值。一旦得以有效利用，大数据就可以变革公司的盈利模式和传统交流方式。规模依然很重要，但是如今重要的是数据的规模，也就是说要掌握大量数据而且要有能力轻松地获取更多的数据。因为最好的的大数据服务都是以创新思维为基础的，所以他们不一定需要大量的原始资本的投入。 第三部分：大数据时代的管理变革07.风险：让数据主宰一切的隐忧如果说互联网时代我们的隐私受到了威胁，那么大师数据时代是否会加重呢？这是大数据的不利影响吗？答案是肯定的，不但如此，大数据还会带来更多的威胁，毕竟大数据的核心思想就是用规模剧增来改变现状。同时还将面对一个新的挑战，即运用大数据预测来判断和惩罚人类的潜在行为，这是对公平公正以及自由意志的一种亵渎，同时也轻视了决策过程中深思熟虑的重要性。 大数据的价值不再单纯来源于它的基本用途，而更多源于它的二次利用。这颠覆了当下隐私保护法以个人为中心的思想：数据收集者必须告知个人，他们收集了哪些数据，作何用途，也必须在收集工作开始之前征得个人的同意；但是大数据时代，很多数据在收集的时候并无意用作其他用途，而最终却产生了很多创新的用途。，所以告知与许可就完全没有意义了。因为它要么太狭隘，限制了大数据潜在价值的挖掘，要么就太空泛而无法真正地保护个人隐私。 在大数据是时代利用技术方法来保护隐私也是天方夜谭。如果所有人的信息本来都已经在数据库里，那么有意识地避免某些信息就是此地无银三百两。另一条技术途径在大部分情况也不行，在小数据时代这样确实可行，但是随着数据量和种类的增多，大数据促进了数据内容的交叉检验。 预测和惩罚，不是因为所做，而是因为将做。结果是我们将生活在一个没有独立选择和自由意志的社会，在这里我们的道德指标将被预测系统所取代，个人一直受到集体意志的冲击。简单的说，如果一切都成为现实，大数据就会把我们禁锢在可能性之中。 卓越的才华并不依赖与数据。我们必须杜绝数据的过分依赖，而是让数据为我们所用，而不让我们成为数据的奴隶。 08.掌控：责任与自由并举的信息管理随着世界开始迈向大数据时代，社会也将经历类似地壳运动，在改变我们许多基本的生活和思考方式的同时，大数据早已在推动我们去重新考虑嘴基本的准则，包括怎么养鼓励其增长极怎么养遏制其潜在威胁。 管理变革1: 个人隐私保护，从个人许可到让数据使用者承担责任。在大数据时代，我们需要设立一个不一样的隐私保护模式，这个模式应该更着重于数据使用者为其行为承担责任，而不是将重心放在收集数据之初取得个人同意上。同时，我们也需要发明并推行新技术方式来触进隐私保护。一个创新途径就是差别隐私，故意让数据模糊处理，促使查询不能显示精确结果，而只有相近的结果，这使得挖出特定个人与特定数据点的联系变得难以实现并且耗费巨大。管理变革2: 个人动因VS预测分析 在大数据时代，关于公正的概念需要重新定义以维护个人动因的想法，即人们有选择自我行为的自由意志，个人可以病应该为她们的行为而非倾向负责。管理变革3: 击碎黑盒子，大数据算法工程师的崛起 大数据的运作是在一个超出我们正常理解范围之上的。“可解释性”正如人工智能届所称的一样，对于不仅想知道“是什么”更想知道“为什么”的人类来说非常重要。可是在大数据背景之下，我们看到大数据预测，运算法则和数据库有变成黑盒子的风险，这个黑盒子不透明，不可解释，不可追踪，因而我们对其信息全无。当一个特定领域变得特别复杂和专门化之后，就会催生出对运用新技术的专门人才的迫切需求。管理变革4: 反数据垄断大亨 数据之于信息社会就如同燃料之于工业革命，是人们进行创新的力量源泉。没有大量鲜活的数据和健全的服务市场，这些创新实现不了。 从核技术到生物工程学其他领域的发展，人类总是先创造出可能危害自己的工具，然后才着手建立保护自己，防范危险的安全机制，在这方面大数据也一样。我们现在的任务就是要意识到新技术的风险，促进其发展然后斩获成果。 结语 正在发生的未来大数据并不是一个充斥着算法和机器的冰冷世界，人类的作用依然无法被完全替代。大数据为我们提供的不是最终答案，只是参考答案，帮助是暂时的，而更好的方法和答案在不久的将来。凡是过去，皆为序曲。更大的数据源于人本身，大数据是一种资源，也是一种工具。它告知信息但不解释信息，它指导人们去理解，但有时也会引起误解，这取决于是否被正确使用。大数据的力量是那么耀眼，我们必须避免被它的光芒所诱惑，并善于发现它固有的瑕疵。]]></content>
      <categories>
        <category>行业观察</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>行业前沿</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交大三年，转瞬即逝]]></title>
    <url>%2F2013%2F11%2F03%2FThree-Years-Of-SJTU%2F</url>
    <content type="text"><![CDATA[这是一个无比惬意的周日!周四通过了论文答辩，周六花了一天的时间完成归档的事情，交大三年工程硕士的学习终于可以画上一个句号了，再也不用纠结论文的事情了！唯一还需要做的就是参加毕业典礼，拿学位证书，而这需要做的仅仅就是等待了。时光就是这么从容，三年前的这个季节，我和菜菜结婚，而三年后的今天，女儿已经半岁了。还记得在上海上课的那一年半，每个周末我比平时上班起床还早，而为了完成项目管理课程的作业，很多时候要和同学一起搞到凌晨，其中艰辛只有自己知道。比身体更疲惫的，是心中对于一些课程问题的纠结，期间甚至还想过转专业的事情，不过庆幸的是我挺了过来。 昨天在从上海回无锡的车上，我一直在想这三年我从交大得到了什么？我花了五六万块钱，和比钱更宝贵的时间和精力，可是想到最后，没有什么特别能总结出来的。不过唯一让自己可以确认的是：通过三年这我证明了一件事情，那就是我做到了自己当初有点不敢想的事情！当然，让我开心的事情还有很多，比如能够认识一些特别好的老师和同学。首先要多谢张艳红老师的项目管理课程，让我们有了6DO这个团队，虽然后来我们做的不是最好的，但是毕竟因为这个团队，才能让我和同学们的关系更加亲密，否则如果只是去上了一些课，然后拿到学位，就未免太遗憾了。其次，要感谢的是赵建军教授，也就是我的论文导师。论文阶段，一直都没有机会跟赵老师见面，直到我答辩通过找他签字的时候才见了他一面。因为我在无锡，去上海不方便，所以赵老师周末专门为我去了一趟学校，因为开题和中期需要其他老师签字，赵老师还带着我跑了一大圈才找齐了签字的老师。赵老师身为交大的正教授，博士生导师，平易近人没有一点架子，自己能够得到他的指导，实在是很幸运的一件事情。最后要说的是：能够和姜总，老袁，一柯，晓东和琦琦一起组成6DO团队，并且相互扶持着通过张总的项目管理课程，一定是我很怀念的时光。虽然以后大家注定还是会因为自己的生活和事业，相互自己的沟通交流会越来越少，但不管怎么样，我们曾经在一起过努力过，都祝愿我们能够越来越好！好了，我是一个容易伤感的人，所以不能让自己沉浸在这种伤感的心绪中，向前看吧！还有更多的事情等着我去做，而我必定也会像这次一样心想事成，当然靠的还是自己踏踏实实，一步一个脚印的努力。]]></content>
      <categories>
        <category>时光漫步</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>上海交大</tag>
        <tag>工程硕士</tag>
      </tags>
  </entry>
</search>
